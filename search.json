[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to R and the tidyverse",
    "section": "",
    "text": "Welcome!\nTo the Introduction to R and the Tidyverse training.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "01_materials_external.html",
    "href": "01_materials_external.html",
    "title": "1  Course Materials",
    "section": "",
    "text": "1.1 Getting Started\nThese materials have been written such that you should be able to follow along without the aid of an instructor.\nTo follow along with the exercises, you will need to download the course datasets and script to your local RStudio.\n# 1. Install and load helper packages\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\n\nlibrary(httr)\nlibrary(jsonlite)\n\n# 2. Copy the `download` function from GitHub into your environment\nsource(\"https://raw.githubusercontent.com/GSK-Biostatistics/intro_to_r_and_the_tidyverse_training/main/download_data.R\")\n\n# 3. Run the function to get your data\ndownload_data(\n  owner    = \"GSK-Biostatistics\",\n  repo     = \"intro_to_r_and_the_tidyverse_training\",\n  path     = \"data\",\n  dest_dir = \"/path/to/your/folder\" # &lt;--- EDIT THIS PATH \n)\nAfter running this code a new folder will be created called data in your chosen location. The folder will contain the data and course script. The script for this course is called full_script.R. This script contains a copy of all of the code from the grey boxes within these materials, as well as the answers to the exercises (note that these are commented out but should run if un-commented).\nThe new folder should look like this:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Materials</span>"
    ]
  },
  {
    "objectID": "01_materials_external.html#getting-started",
    "href": "01_materials_external.html#getting-started",
    "title": "1  Course Materials",
    "section": "",
    "text": "Tip\n\n\n\nIn the code below, change \"/path/to/your/folder\" to the actual location on your computer where you want to save your work (e.g., \"~/Tidyverse_Training\").",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Materials</span>"
    ]
  },
  {
    "objectID": "01_materials_external.html#initialising-the-course-project",
    "href": "01_materials_external.html#initialising-the-course-project",
    "title": "1  Course Materials",
    "section": "1.2 Initialising the Course ‘Project’",
    "text": "1.2 Initialising the Course ‘Project’\nNow you have downloaded the materials, open the folder you created with the data saved in it and click on the RStudio project file (intro_to_r_and_the_tidyverse_training.Rproj) to start a new project. This ensures all the relative paths work as expected. We will briefly discuss further benefits of RStudio Projects later in the course.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Materials</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html",
    "href": "02_r_rstudio.html",
    "title": "2  Introduction to R and RStudio",
    "section": "",
    "text": "2.1 Ownership of R\nR is free and open source under a GPL-2 license. This means that you can download it at home and, if you want, see how it has been written. It also means that you get a “ABSOLUTELY NO WARRANTY” message every time you load up R. But don’t let that put you off!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#ownership-of-r",
    "href": "02_r_rstudio.html#ownership-of-r",
    "title": "2  Introduction to R and RStudio",
    "section": "",
    "text": "2.1.1 A Note on Using R for Regulatory Work\nDespite common opinion, there is no reason why R cannot be used for regulatory work. It is true that the FDA require the use SAS transport files for a submission, however these are not a proprietary format and you can produce them using R. And even this requirement could disappear in the future in favour of a more open format such as XML.\nR is widely used at the FDA (there are several presentations available online from people at the FDA stating this). The R Foundation have also released an official document outlining their understanding of how R can be used in a regulated clinical trial environment: https://www.r-project.org/doc/R-FDA.pdf. However, R is still not commonly used for submission work, and hence for clinical analysis.\nWhenever discussing the use of R in a regulatory environment always remember that there is a clear distinction between: the base R language, that has been built up over several years and widely tested by the R community; and the publically available R packages, which anyone can develop (and may, or may not, do what they are supposed to).\nTo learn more about how the industry is addressing this question, it is worth visiting the “R Validation Hub”, www.pharmar.org. The Hub is an industry-wide effort to agree upon some basic principles regarding the use of R in a regulatory setting.\nThe R Validation Hub have produced a white paper entitled, “A Risk-based Approach for Assessing R package Accuracy within a Validated Infrastructure”.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#working-in-rstudio",
    "href": "02_r_rstudio.html#working-in-rstudio",
    "title": "2  Introduction to R and RStudio",
    "section": "2.2 Working in RStudio",
    "text": "2.2 Working in RStudio\nLet’s start off by watching a short video from RStudio showcasing their IDE. Don’t worry, there will be a deep-dive into each part that the presenter goes over and even more!\n\n\nNotice how the presenter covered the four different panes of RStudio. We are going to follow almost the same method.\n\nExplore the Console by doing some Simple Arithmetic\nWrite our first R script by using the Scripting Editor.\nDiscuss objects while looking at the Environment Pane\nLook at a function and its parameters in the Help Tab.\n\nThere are more Tabs within each Pane. We will cover the remaining tabs at the end of this Chapter using our Script to do another walkthrough. The RStudio IDE is powerful, but can be overwhelming so start small and expand your abilities as you code.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#simple-arithmetic-using-the-console",
    "href": "02_r_rstudio.html#simple-arithmetic-using-the-console",
    "title": "2  Introduction to R and RStudio",
    "section": "2.3 Simple arithmetic using the Console",
    "text": "2.3 Simple arithmetic using the Console\nLike most scripting languages R provides us with a console for direct interaction. In other words we can directly ask R questions without the need for scripts. This course contains many simple, “one line” examples that we will execute directly in the console.\nLet’s enter a few R statements into the Console and use the return key to execute it. Results are displayed right under the statement entered.\n\n3 + 4\n3 - 4\n5 * 8\n\nPlease, type the above statements into the console, pressing the return key after each one and see that it matches up with the below image. Take a note on how R indicates that something is an output.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#creating-objects",
    "href": "02_r_rstudio.html#creating-objects",
    "title": "2  Introduction to R and RStudio",
    "section": "2.4 Creating Objects",
    "text": "2.4 Creating Objects\nSo far we have simply printed output to the console. We can also store any objects and use them later on. The convention in the R community is to use &lt;- to assign and store objects, however = may also be used.\n\n&gt; # Methods of assigning/storing values\n&gt; x &lt;- 5\n&gt; y = 6\n&gt; z &lt;- \"GSK\"\n\nObjects are created in our global environment, similar to the ‘work’ area in SAS. We can always see a list of created objects in the ‘Environment’ tab with a little information about their structure. Additionally, you can use the str function to learn more about an object’s structure, or simply type it’s name in the console to print it out.\n\n\n\nFigure 3: Global Environment\n\n\nTo produce a list of these objects in the console we can call either of the in-built functions ls() or objects()\n\n&gt; # Things I have created\n&gt; objects()\n\n [1] \"act\"             \"act_full\"        \"act_long\"        \"dm\"             \n [5] \"pandoc_dir\"      \"params\"          \"quarto_bin_path\" \"sl\"             \n [9] \"theoph\"          \"vs\"              \"x\"               \"y\"              \n[13] \"z\"              \n\n\nThe broom symbol in the environments tab allows us to delete all objects that we have created. Alternatively we can do so programatically.\n\n&gt; # Remove all objects from workspace\n&gt; rm(list=ls())\n\n\n2.4.1 Naming Conventions\nAt this point it is worth stressing that R is case sensitive and so “x” and “X” are not the same! Names can be as long as we like and use any combination of upper case, lower case, numerics, underscores and dots. However, they may not start with a number or underscore. Today, most R users either use camelCase or snake_case to separate out words when naming objects. At GSK we have opted to use the tidyverse style guide, which advocates snake_case.\n\n\n2.4.2 Using Objects\nTo use the objects we just reference them in exactly the same way that we created them.\n\n&gt; # Use values that have been previously stored\n&gt; x + y\n\n[1] 11\n\n&gt; # Now let's do something silly to get a really helpful error message!\n&gt; x + z\n\nError in `x + z`:\n! non-numeric argument to binary operator\n\n\nData types cannot usually be combined so it is important to recognise the basic types of data (and error messages) that exist in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#our-first-r-script",
    "href": "02_r_rstudio.html#our-first-r-script",
    "title": "2  Introduction to R and RStudio",
    "section": "2.5 Our first R Script",
    "text": "2.5 Our first R Script\nLet’s create our first R script, by navigating to the top-left corner. First, we click the green plus sign and select R Script. There are several other ways to create a new script, one of which is Crtl+Shift+N, or using File &gt; New File &gt; R Script.\n\n\n2.5.1 The Script Editor\nThe script editor is very much like the SAS script editor, or any other script editor for that matter. Syntax highlighting improves readability and there is a first line layer of code recognition which can identify common scripting errors such as a bracket or quotation mark that hasn’t been opened/closed.\n\nOther default features of the editor include automatic indentation, closing of brackets, color-coded brackets, and quotations and auto-completion of code. All of these features can be modified or switched off via the\nCode menu: Tools &gt; Global Options &gt; Code.\n\nTo execute the code that we write in the script editor we can either click on the Run button at the top of the window or use Ctrl + Enter on the keyboard. By default, code is executed line by line depending on where the cursor is located. To run sections of code (or the entire script) we must highlight the code that we want to run. Alternatively, we can run the entire script by saving and clicking the Source button.\nNow, let’s work on our first script. First, let’s save our Unititled file as my_first_R_script.R in the folder /Home/gsk_R_training\nIn this brief walk through we will create and summarise some data. We will learn a lot more about what exactly is happening later in the course.\nNow, let’s create some dummy data for weight and height. Note that the list of 5 numbers is wrapped in parentheses with a c in front. This is how R creates a “vector” (similar to a column of data). We have just created two such objects called weight and height.\n\n&gt; weight &lt;- c(70.9, 87.2, 90.8, 68.1, 72.6)\n&gt; height &lt;- c(170, 185, 178, 175, 180)\n\nLet’s find the bmi of the 5 subjects that we created. Notice how the output is reported back to us.\n\n&gt; weight/ (height / 100)^2\n\n[1] 24.53287 25.47845 28.65800 22.23673 22.40741\n\n\nNow, lets find the mean of the height variable, by using the function mean. After you type the word mean in your script, hit tab and see what appears. If you press F1 it wil bring up a help page for the mean function. You can also type ?mean.\n\n\n&gt; mean(height)\n\n[1] 177.6\n\n\nIn our R script, lets save the mean(height) as mean_hgt and weight/ (height / 100)^2 as bmi.\n\n&gt; mean_hgt &lt;- mean(height)\n&gt; bmi &lt;- weight/ (height / 100)^2\n\nWhere did they go? There is no longer any output in the console! Remember, you can view objects in the Environment tab in the upper right hand window of Rstudio.\n\n\n\n2.5.2 Functions and Help\nR has many built-in functions to aid you in your work, typically the R community refers to these as base-R functions. Where a base-R function is lacking or not available, then enterprising folks have used R’s powerful package building process to supplement base-R functions. We will cover packages very soon, specifically the tidyverse package. Now lets take another look at our mean function again. You can type ?mean to bring up documentation and examples of how to use the mean function or tab and f1 right you type the function.\n\nIf you scroll to the bottom of the help page, you can see an example. Try to run the example in your console by highligting the text and clicking ctrl+enter . What is the value of xm?\n\n\n2.5.3 Clearing History, Console, Environment\nThe console can be cleared by choosing the menu item Edit -&gt; Clear Console. Else you can use the keyboard shortcut Ctrl + L.\nYou can also clear the console by clicking the broom.\n\nTo clear the Environment Variables you can click another broom. It is a good programming practice to clear your environmental variables after you are finish writing your script and then rerun it.\n\n\n\n2.5.4 Restarting or Terminating our Session\nSometimes it makes sense to restart with a clean slate (eg to test code). The current R session can be restarted by choosing the menu item Session -&gt; Restart R. This removes all objects and unloads all packages.\nNote that closing the browser does not terminate the R session. To completely terminate the session you should use the orange ‘power button’ icon in the top right hand part of the window.\nIt is possible to save objects (eg large data sets that take a long time to import) using the save function but this is not covered on this course.\n\n\n2.5.5 A Paneful Tour\nThe interface of RStudio consists of 4 main panes and sub-panes within those main panes\nAdditional panes can appear for additional functionality, e.g. the R Markdown or Git pane. Note, the Editor pane is only visible if at least one source code file is open.\n\nEditor pane for editing source code files like R scripts or R Markdown files (top left part in the screenshot)\nConsole pane for running R code interactively\nTerminal pane for using a terminal within RStudio\nJobs pane for running R jobs\nEnvironment pane displaying objects created in a R session\nHistory pane displaying the statement history\nConnections pane for connections to databases\nFiles pane for browsing and handling files/directories\nPlots pane displaying plots\nPackages pane for installing and updating R packages\nHelp pane displaying R help pages\nViewer pane displaying rendered R Markdown documents and Shiny apps\n\nAs you work through this training keep in mind that this comes with accompanying script that contains all the code and exercise solutions: This script can be found at /home/gsk_R_training/tidyverse.R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "02_r_rstudio.html#packages",
    "href": "02_r_rstudio.html#packages",
    "title": "2  Introduction to R and RStudio",
    "section": "2.6 Packages",
    "text": "2.6 Packages\nAn R package is just a collection of R objects. The majority of these objects are functions but may also be data or other forms of object.\nR is essentially a collection of “packages”. An R package is what other programming languages usually call a “library” (or “module” in SAS). In other words it is a bundle of code that implements some functionality that extends the language. This course is based around one package in particular, called “tidyverse” (which is itself a collection of other packages).\nThe R installation itself is actually just a collection of around 30 packages, several of which are automatically loaded when you start an R session:\n\n&gt; # R packages loaded in my session:\n&gt; search()\n\n [1] \".GlobalEnv\"        \"package:haven\"     \"package:lubridate\"\n [4] \"package:forcats\"   \"package:stringr\"   \"package:dplyr\"    \n [7] \"package:purrr\"     \"package:readr\"     \"package:tidyr\"    \n[10] \"package:tibble\"    \"package:ggplot2\"   \"package:tidyverse\"\n[13] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n[16] \"package:utils\"     \"package:datasets\"  \"package:methods\"  \n[19] \"Autoloads\"         \"package:base\"     \n\n\nThe vast majority of R packages contain utility functions for performing data manipulation or analysis, or for drawing graphics. In many cases they also come packed with examples and even dummy data sets to use.\nThe 30 packages that make up the base R installation are maintained by the R Core Team. However there are also more than 10,000 publically available R packages available on CRAN (The Comprehensive R Archive Network).\n\n\n\n2.6.1 Loading Packages\nEach time we start a new R session, only a handful of our installed packages are actually loaded.\n\n&gt; # These packages are currently loaded in my environment:\n&gt; search()\n\n [1] \".GlobalEnv\"        \"package:haven\"     \"package:lubridate\"\n [4] \"package:forcats\"   \"package:stringr\"   \"package:dplyr\"    \n [7] \"package:purrr\"     \"package:readr\"     \"package:tidyr\"    \n[10] \"package:tibble\"    \"package:ggplot2\"   \"package:tidyverse\"\n[13] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n[16] \"package:utils\"     \"package:datasets\"  \"package:methods\"  \n[19] \"Autoloads\"         \"package:base\"     \n\n\nThis course is based around the tidyverse, which is not loaded by default. We can either load the package manually by checking the box next to the named package in the packages menu or, as is more common when writing scripts, we can add a statement library(PACKAGENAME) to our script.\n\n&gt; # Run this or the course won't be much fun!\n&gt; library(tidyverse)\n\nIt is good practice to place all of our library calls at the top of our script. Thus, when sharing a script anyone else can immediately see what they need to have installed in order to use the script.\nThe ‘tidyverse’ is an umbrella term/package for a number of other packages. Calling library(tidyverse) actually loads several useful packages including readr, dplyr, tidyr, stringr, forcats and ggplot2. This is a great short-hand when working interactively but for formal code development it is best practice to load the components that you actually need individually:\n\n&gt; library(readr)\n&gt; library(dplyr)\n&gt; library(tidyr)\n&gt; # etc.\n\nWe will need to install the required packages ourselves. There are a few ways to do so but the simplest is to use the Packages tab in RStudio. To install a package we click on the Packages tab and then click on the Install icon.\nThe Install icon gives us options to install locally, or from repositories such as CRAN. We simply type the package name and click Install. Always leave the ‘dependencies’ check-box checked as this also installs any other packages that your chosen package needs in order to work!\n\n\n\nFigure 1: Installing a Package",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R and RStudio</span>"
    ]
  },
  {
    "objectID": "03_vectors.html",
    "href": "03_vectors.html",
    "title": "3  Data Types and Vectors",
    "section": "",
    "text": "3.1 Data Types\nR has 4 basic data types (modes) from which almost everything else is built upon. These are:\n# Numeric\n3 + 7\n\n[1] 10\n\n6 - 14\n\n[1] -8\n\n5*9\n\n[1] 45\n\n100/3\n\n[1] 33.33333\n\n# Character\n\"Hello! I work at GSK\"\n\n[1] \"Hello! I work at GSK\"\n\n# Logical\n6 &gt; 7\n\n[1] FALSE\n\nis.numeric(12)\n\n[1] TRUE\nNote that the logical values TRUE and FALSE are reserved words, meaning that we cannot overwrite (mask) them. In the examples above the logicals were produced by asking a question. It is also possible to create them directly (x &lt;- TRUE). When doing so, they must be written exactly using capital letters and without quotation marks. We will look at the usage of logicals more closely later on in the course.\nThe terms used above are formal definitions in R. The mode function lets us query the type of any element.\nmode(5)                 # numeric\n\n[1] \"numeric\"\n\nmode(\"have a guess\")    # character\n\n[1] \"character\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#data-types",
    "href": "03_vectors.html#data-types",
    "title": "3  Data Types and Vectors",
    "section": "",
    "text": "numeric\ncharacter\nlogical\ncomplex (which we will ignore in this course)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#combining-elements-to-make-a-vector",
    "href": "03_vectors.html#combining-elements-to-make-a-vector",
    "title": "3  Data Types and Vectors",
    "section": "3.2 Combining Elements to Make a Vector",
    "text": "3.2 Combining Elements to Make a Vector\nA vector is a collection of elements/values that have the same type or “mode”. In R, vectors technically have no dimension but we will usually treat them as columns of data in a dataset (data frame).\nWe can easily create vectors using the c function to “combine” one or more elements together.\n\n# Numeric vectors\nc(5, 42, 99)\n\n[1]  5 42 99\n\nc(6.423, 7.324, 9.225)\n\n[1] 6.423 7.324 9.225\n\n# Character vectors\nc(\"I\", \"have\", \"four\", \"elements\")\n\n[1] \"I\"        \"have\"     \"four\"     \"elements\"\n\n\nWe can also combine vectors using c.\n\n# Create a couple of vectors\nvec1 &lt;- c(5,9,2)\nvec1\n\n[1] 5 9 2\n\nvec2 &lt;- c(7,8,1)\nvec2\n\n[1] 7 8 1\n\n# Combine the vectors\nvec3 &lt;- c(vec1, vec2)\nvec3\n\n[1] 5 9 2 7 8 1\n\n\nNB: A scalar (single value) is technically just a vector with 1 element.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#sequences",
    "href": "03_vectors.html#sequences",
    "title": "3  Data Types and Vectors",
    "section": "3.3 Sequences",
    "text": "3.3 Sequences\nIn addition to the c function, R contains a number of useful operators and utility functions for creating vectors. First we look at the seq function for generating sequences.\nThe seq function takes self-explanatory arguments “from” and “to”. By default, the incremental value is 1. We can optionally provide either “by” or “length” to change this.\n\n# Simple sequence\nseq(from = 1, to = 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# The same, but without specifying the arguments:\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# Counting down\nseq(80, 60, by = -5)\n\n[1] 80 75 70 65 60\n\n# Using 'by' and 'length'\nseq(from = 1, to = 10, by = 0.5)\n\n [1]  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0  7.5  8.0\n[16]  8.5  9.0  9.5 10.0\n\nseq(from = 10, to = 50, length = 5)\n\n[1] 10 20 30 40 50\n\n\nIf we simply need a sequence of integers then the : operator provides a simple shortcut.\n\n1:50\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\n\n3.3.1 Repeating Values\nThe rep function allows us to repeat a value(s). The arguments times and each provide us with some control of how the repetition is performed.\n\n# Single values\nrep(1, times = 6)\n\n[1] 1 1 1 1 1 1\n\nrep(\"z\", times = 3)\n\n[1] \"z\" \"z\" \"z\"\n\n# Vectors\nvec1  # Reminder of what this is\n\n[1] 5 9 2\n\nrep(vec1, times = 4)\n\n [1] 5 9 2 5 9 2 5 9 2 5 9 2\n\nrep(vec1, each = 4)\n\n [1] 5 5 5 5 9 9 9 9 2 2 2 2\n\nrep(vec1, times = c(5, 4, 6))\n\n [1] 5 5 5 5 5 9 9 9 9 2 2 2 2 2 2\n\n# More advanced example\nn_subj &lt;- 5\nn_visits &lt;- 4\nSUBJID &lt;- rep(1:n_subj, each = n_visits)\nSUBJID\n\n [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5\n\nVISITNUM &lt;- rep(1:n_visits, n_subj)\nVISITNUM\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n\n\n\n3.3.2 Missing data\nIn R, missing data is represented by NA. The term NA is a reserved word in R. Like the reserved logical terms TRUE and FALSE, NA must be written exactly as it is written here, i.e. in capitals and without quotation marks, regardless of whether the data in question is numeric, character, or logical.\n\n# Missing numeric\nmis_num &lt;- c(1,2,NA,4)\nmis_num\n\n[1]  1  2 NA  4\n\n# Missing character\nmis_let &lt;- c(\"G\", NA, \"K\")\nmis_let\n\n[1] \"G\" NA  \"K\"\n\n# Missing logical\nmis_log &lt;- c(mis_num &gt; 5)\nmis_log\n\n[1] FALSE FALSE    NA FALSE",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#vector",
    "href": "03_vectors.html#vector",
    "title": "3  Data Types and Vectors",
    "section": "3.4 EXERCISE",
    "text": "3.4 EXERCISE\n\nLoad the tidyverse package\nCreate a vector that stores the values 4, 9, 2, 1, 6, and 3\n\nAdd 1 to every element in your vector (easier than you may think)\nAdd a missing value to the end (i.e. the 7th position)\nAdd 1 to every element again and observe what happens with the missing value\n\nCreate a vector containing the numbers 1 to 20, incremented by 1\nCreate a sequence of 3 numbers between 18 and 65\nRepeat the word “GSK” 50 times\n\nExtra\n\nCreate a vector with subject numbers 1, 2 and 3 where 1 is repeated 6 times, 2 is repeated 4 times, and 3 is repeated 5 times.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#simulating-data",
    "href": "03_vectors.html#simulating-data",
    "title": "3  Data Types and Vectors",
    "section": "3.5 Simulating Data",
    "text": "3.5 Simulating Data\nIn order to populate vectors and data frames (see next chapter) we can also simulate data. This is not a simulation course but we will briefly look at some of the easy ways in which we can simulate data, either via known distributions or by sampling from existing data.\n\n3.5.1 Distributions\nR has a number of statistical distributions “built in”, a huge number more available through add-on packages. The built-in distributions all follow a consistent naming convention and structure. First of all each distribution has been given a short-form. For example, the normal distribution has the short form, “norm”. A handful of common short forms are listed below:\n\n\n\n\n\nShort Form\nDistribution\n\n\n\n\nnorm\nNormal\n\n\npois\nPoisson\n\n\nbinom\nBinomial\n\n\nf\nF\n\n\nt\nStudent’s t\n\n\nunif\nUniform\n\n\nweibull\nWeibull\n\n\ngamma\nGamma\n\n\nchisq\nChi-squared\n\n\n\n\n\nSee help(\"Distributions\") for more information on available distributions.\nTo each of the short forms we may apply one of four pre-fixes, d, p, q, r. When appended to a short-form distribution, the prefixes respectively provide:\n\nd - the probability density function, PDF, for given values\np - the cumulative distribution function, CDF, for given quantiles\nq - the inverse distribution function for given probabilities\nr - randomly generated numbers from the distribution for a given n\n\nSo for example if we wanted to know the PDF of a normal distribution between the values of -3 and 3 we would generate a sequence and then use a function, dnorm to find the densities. For example,\n\n# Values of interest \nx &lt;- seq(-3, 3, by = .01)\nPDF &lt;- dnorm(x)\n\n# Now let's plot using ggplot2\nggplot() + \n  geom_line(aes(x = x, y = PDF))\n\n\n\n\n\n\n\n\n\n\n3.5.2 Sampling From a Distribution\nFrom a simulation perspective we are normally interested in sampling values from a known distribution. This is very straightforward. For example, if we want 200 numbers randomly sampled from a normal distribution we would write, rnorm(200). Which we might then plot as a histogram.\n\n# Values of interest \nx &lt;- rnorm(200)\n\n# Now let's plot using ggplot2\nggplot() + \n  geom_histogram(aes(x), bins = 20,\n                 colour = I(\"grey\"), fill = I(\"lightblue\"))\n\n\n\n\n\n\n\n\n\n\n3.5.3 Sampling from a Set of Values\nAs well as sampling from distributions we may also sample from a discrete set of values using the sample function. The sample function requires us to provide a vector to sample from, a number of samples to take. The function contains additional options for whether we wish to sample with replacement (replace) and/or whether we wish to give each value an equal chance of being sampled (prob).\nHere are a few examples,\n\n# Generate some subjects\ntreatment &lt;- c(\"GSK\", \"Other\")\n\n# Sample values from this set, with replacement\nsample(treatment, 50, replace = TRUE)\n\n [1] \"Other\" \"Other\" \"Other\" \"GSK\"   \"GSK\"   \"Other\" \"Other\" \"Other\" \"Other\"\n[10] \"Other\" \"GSK\"   \"GSK\"   \"Other\" \"GSK\"   \"GSK\"   \"Other\" \"GSK\"   \"Other\"\n[19] \"GSK\"   \"Other\" \"GSK\"   \"Other\" \"Other\" \"GSK\"   \"Other\" \"GSK\"   \"Other\"\n[28] \"Other\" \"GSK\"   \"GSK\"   \"Other\" \"GSK\"   \"Other\" \"Other\" \"GSK\"   \"Other\"\n[37] \"Other\" \"GSK\"   \"GSK\"   \"Other\" \"Other\" \"GSK\"   \"Other\" \"Other\" \"Other\"\n[46] \"GSK\"   \"Other\" \"Other\" \"Other\" \"GSK\"  \n\n# Sample again but this time we want more 'Other' in our population,\n# rougly 4 'Other' for every 'GSK' entry\nsample(treatment, 50, replace = TRUE, prob=c(1,4))   \n\n [1] \"GSK\"   \"Other\" \"Other\" \"GSK\"   \"Other\" \"Other\" \"Other\" \"Other\" \"Other\"\n[10] \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"GSK\"   \"Other\" \"Other\"\n[19] \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"Other\"\n[28] \"Other\" \"Other\" \"Other\" \"Other\" \"GSK\"   \"Other\" \"GSK\"   \"Other\" \"GSK\"  \n[37] \"GSK\"   \"Other\" \"GSK\"   \"Other\" \"Other\" \"Other\" \"Other\" \"Other\" \"GSK\"  \n[46] \"Other\" \"Other\" \"Other\" \"Other\" \"Other\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "03_vectors.html#an-introduction-to-data-frames",
    "href": "03_vectors.html#an-introduction-to-data-frames",
    "title": "3  Data Types and Vectors",
    "section": "3.6 An Introduction to Data Frames",
    "text": "3.6 An Introduction to Data Frames\nThere are actually several structures that can be used to store data in R. The most common structure, and the one we will work with on this course, is called a data.frame. Like a SAS dataset, a data frame is a collection of columns (vectors), each of which may have a different type (mode).\nThere are several built-in data frames, contained within the “datasets” package\n\nobjects(\"package:datasets\")\n\nWe can use the head and tail functions to view the first or last few rows of a data frame\n\n# In-built airquality data\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\ntail(airquality)\n\n    Ozone Solar.R Wind Temp Month Day\n148    14      20 16.6   63     9  25\n149    30     193  6.9   70     9  26\n150    NA     145 13.2   77     9  27\n151    14     191 14.3   75     9  28\n152    18     131  8.0   76     9  29\n153    20     223 11.5   68     9  30\n\n# Specifying a custom number of rows to display\nhead(airquality, 1)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types and Vectors</span>"
    ]
  },
  {
    "objectID": "04_data_frames.html",
    "href": "04_data_frames.html",
    "title": "4  Welcome to the tidyverse!",
    "section": "",
    "text": "4.1 Tibbles (Special Data Frames)\nIf you have used R previously, most of what you have seen so far should be relatively familiar. Much of the rest of this course focuses on relatively new structures and concepts which have been predominantly developed by Hadley Wickham, an R Foundation member and RStudio employee, and his team.\nOne of the key themes that you will notice is that functions in the tidyverse have a single purpose! Functions do just one thing and do it well. Further, they process the inputs in a consistent way so that you always know what to expect on the other side.\nThe first tidyverse concept that we shall look at is a tibble.\nTibbles are not part of base R and so to see what they look like we need to load the tibble package.\nlibrary(tibble)  # NB: loading the dplyr/tidyverse package also loads tibble\nTo the user, there is very little difference between a tibble and a data frame. The main difference is the way they print. In particular, a tibble limits the number of rows and columns that actually print. Instead, the dimensions are printed, and if there are too many columns to fit on the screen these are simply listed out. Finally the underlying data type for each column is also displayed. For numeric data, the underlying type is displayed. These are dbl (double) or int (integer) although we rarely have to worry about this distinction in practice.\nair_tib &lt;- tibble(airquality)\nair_tib\n\n# A tibble: 153 × 6\n   Ozone Solar.R  Wind  Temp Month   Day\n   &lt;int&gt;   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    41     190   7.4    67     5     1\n 2    36     118   8      72     5     2\n 3    12     149  12.6    74     5     3\n 4    18     313  11.5    62     5     4\n 5    NA      NA  14.3    56     5     5\n 6    28      NA  14.9    66     5     6\n 7    23     299   8.6    65     5     7\n 8    19      99  13.8    59     5     8\n 9     8      19  20.1    61     5     9\n10    NA     194   8.6    69     5    10\n# ℹ 143 more rows\nA tibble is actually just an extension to a data frame. As such we will generally use the term “data frame” throughout this course.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Welcome to the tidyverse!</span>"
    ]
  },
  {
    "objectID": "04_data_frames.html#creating-data-frames",
    "href": "04_data_frames.html#creating-data-frames",
    "title": "4  Welcome to the tidyverse!",
    "section": "4.2 Creating Data Frames",
    "text": "4.2 Creating Data Frames\nTypically, we import data from other sources (see next chapter). However, the flexibility of R and the tidyverse allows us to easily generate our own datasets from scratch. This can be particularly useful for simulation.\nA data frame is simply a structured collection of vectors where each vector is stored as a ‘column’ (technically, a data frame is a ‘list’ of vectors). To create a data frame we use the tidyverse function tibble. We separate columns by a comma. Each new column is given a name to the left of an equals sign, with the values that it will hold entered to the right of the equals.\n\nmy_df &lt;- tibble(SUBJID = rep(1:3, each = 2),\n               VISITNUM = rep(1:2, 3))\nmy_df\n\n# A tibble: 6 × 2\n  SUBJID VISITNUM\n   &lt;int&gt;    &lt;int&gt;\n1      1        1\n2      1        2\n3      2        1\n4      2        2\n5      3        1\n6      3        2\n\n\nThe tibble function adds columns sequentially, meaning that we can add a column and then use it to generate another column, all in one function call. For example,\n\ntibble(HEIGHT = c(182, 164),\n       WEIGHT = c(74, 67),\n       BMI = WEIGHT^2/HEIGHT)\n\n# A tibble: 2 × 3\n  HEIGHT WEIGHT   BMI\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1    182     74  30.1\n2    164     67  27.4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Welcome to the tidyverse!</span>"
    ]
  },
  {
    "objectID": "04_data_frames.html#the-crossing-function",
    "href": "04_data_frames.html#the-crossing-function",
    "title": "4  Welcome to the tidyverse!",
    "section": "4.3 The crossing Function",
    "text": "4.3 The crossing Function\nThe crossing Function lives in the tidyr package (which is automatically loaded using library(tidyverse)). The function generates a data frame containing all combinations of the values that we provide it with. This is particularly useful for simulation. For example, we could use the function to create visits for each subject in a study:\n\nlibrary(tidyr) \nmy_df &lt;- crossing(SUBJID = 1:3, VISITNUM = 1:2)\nmy_df\n\n# A tibble: 6 × 2\n  SUBJID VISITNUM\n   &lt;int&gt;    &lt;int&gt;\n1      1        1\n2      1        2\n3      2        1\n4      2        2\n5      3        1\n6      3        2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Welcome to the tidyverse!</span>"
    ]
  },
  {
    "objectID": "04_data_frames.html#extracting-columns-from-data-frames",
    "href": "04_data_frames.html#extracting-columns-from-data-frames",
    "title": "4  Welcome to the tidyverse!",
    "section": "4.4 Extracting Columns from Data Frames",
    "text": "4.4 Extracting Columns from Data Frames\nThe ‘modern’ way to extract a column from a data frame is to use the pull function (from the dplyr package). The pull function takes two arguments: the name of the data frame, and the name of the column that we wish to extract. The extracted column is returned as a vector.\n\nlibrary(dplyr)\nmy_df\n\n# A tibble: 6 × 2\n  SUBJID VISITNUM\n   &lt;int&gt;    &lt;int&gt;\n1      1        1\n2      1        2\n3      2        1\n4      2        2\n5      3        1\n6      3        2\n\n# Extract the SUBJID column\npull(my_df, SUBJID)\n\n[1] 1 1 2 2 3 3\n\n\nWe will look at subsetting and other operations later in the course.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Welcome to the tidyverse!</span>"
    ]
  },
  {
    "objectID": "04_data_frames.html#crossing",
    "href": "04_data_frames.html#crossing",
    "title": "4  Welcome to the tidyverse!",
    "section": "4.5 EXERCISE",
    "text": "4.5 EXERCISE\n\nCreate a data frame, my_df, containing subject numbers 1 to 20, some random ages between 18 and 65 and trial status “Ongoing” or “Completed”\nCreate a data frame containing all possible combinations of COUNTRY (“UK”, “USA”, “FRA”), STATUS (“Ongoing”,“Completed”) and TRT (“GSK”, “OTHER”)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Welcome to the tidyverse!</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html",
    "href": "05_importing_and_exporting_data.html",
    "title": "5  Importing/Exporting Data",
    "section": "",
    "text": "5.1 Importing Text Files\nNatively, R has very good support for many file formats. For example, functions such as read.csv or the more generic read.table can be used to read in CSV files and other delimited text files. The foreign package can also be used to read in SAS transport files.\nIn this section we look at tidyverse functions for importing/exporting data. Although the tidyverse functions don’t always offer a great deal more in terms of functionality they are generally faster and more consistent than their base R counterparts.\nThe tidyverse functions that we will use for importing and exporting text files are contained in the readr package. Note that readr is loaded by default when loading tidyverse.\nlibrary(readr)\n\n# Alternatively\nlibrary(tidyverse)\nThe readr package has many functions but the import ones all begin read_* and the export ones all begin write_*.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#reading-in-a-csv",
    "href": "05_importing_and_exporting_data.html#reading-in-a-csv",
    "title": "5  Importing/Exporting Data",
    "section": "5.2 Reading in a CSV",
    "text": "5.2 Reading in a CSV\nThe read_csv function is a special case of the read_delim function, a function that allows us to read in text files with a variety of different delimiters and structures. The read_csv function enables us to read in a CSV file. As always, we must give the imported data a name, else it is simply printed to screen. The named data is imported as a tbl_df data frame.\n\n# Read in and save as `theoph`\n# The \".\" represents the current working directory so this is a relative path\ntheoph &lt;- read_csv(\"./data/theoph.csv\")\n\n\n# Now print\ntheoph\n\n# A tibble: 132 × 5\n   SUBJID    WT  DOSE  TIME  CONC\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1  79.6  4.02  0     0.74\n 2      1  79.6  4.02  0.25  2.84\n 3      1  79.6  4.02  0.57  6.57\n 4      1  79.6  4.02  1.12 10.5 \n 5      1  79.6  4.02  2.02  9.66\n 6      1  79.6  4.02  3.82  8.58\n 7      1  79.6  4.02  5.1   8.36\n 8      1  79.6  4.02  7.03  7.47\n 9      1  79.6  4.02  9.05  6.89\n10      1  79.6  4.02 12.1   5.94\n# ℹ 122 more rows\n\n\n\n5.2.1 File Paths\nNote that we specified the file path using forward slashes, i.e. \"/\". The “backslash, \"\\\", is an escape key and has special meaning (or at least what comes after it has a meaning). For example \"\\n\" means ‘return/enter’, \"\\t\" means ‘tab’ and confusingly \"\\\\\" means ‘backslash’! Basically, you must either replace all of the backslashes with forward slashes or add a second backslash at each location.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#reading-in-data-from-sas",
    "href": "05_importing_and_exporting_data.html#reading-in-data-from-sas",
    "title": "5  Importing/Exporting Data",
    "section": "5.3 Reading in Data from SAS",
    "text": "5.3 Reading in Data from SAS\nWe can read both the “.XPT” (a.k.a. “SAS transport file”) and “.SAS7BDAT” formats into R by making use of the haven package. The SAS transport file (version 5) is an open format and can be read in by making use of the haven read_xpt function. The “.SAS7BDAT” files can be read in by making use of the haven read_sas function.\nRStudio understands the concept of labels and the RStudio data viewer is arguably better than the one in PC SAS!!!\nThere are other packages, e.g. foreign and SASXport, which have similar functionality when it comes to importing SAS transport files. However, we use haven for reasons of consistency and efficiency.\n\n# Load the package\nlibrary(haven)\n\n\n# Read in the data (remembering file extension)\ndm &lt;- read_sas(\"./data/dm.sas7bdat\")\n\n\n# View the data\ndm    # or try View(dm)\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 2 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 4 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 5 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 6 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 7 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n 8 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#the-working-directory",
    "href": "05_importing_and_exporting_data.html#the-working-directory",
    "title": "5  Importing/Exporting Data",
    "section": "5.4 The Working Directory",
    "text": "5.4 The Working Directory\nAll R sessions have a working directory. On Windows this is usually something like \"C:/Users/[mudid]/Documents\". This is the directory that R looks in by default when we attempt to import data. Similarly, it’s where R writes to by default. It’s also the default if sourcing other R scripts. We can find out what our working directory is via the getwd function and list the files within it using the list.files function.\n\n# What is my current working directory?\ngetwd()\n\n\n\n[1] \"/home/runner/work/intro_to_r_and_the_tidyverse_training/intro_to_r_and_the_tidyverse_training/data\"\n\n\n\n# What files are in the working directory?\nlist.files()\n\n\n\n [1] \"act.sas7bdat\"     \"act.xpt\"          \"actFull.sas7bdat\" \"actFull.xpt\"     \n [5] \"actLong.sas7bdat\" \"actLong.xpt\"      \"dataset.sas7bdat\" \"dm.sas7bdat\"     \n [9] \"dm.xpt\"           \"pft.sas7bdat\"     \"pft.xpt\"          \"sl.sas7bdat\"     \n[13] \"sl.xpt\"           \"theoph.csv\"       \"vs.sas7bdat\"      \"vs.xpt\"          \n\n\nWe can change/set the working directory using the setwd function. The advantage of setting up a working directory is that we needn’t specify full file paths every time we import/export data. This also makes our code more transferable as our username isn’t hard-coded into our scripts!\n\n# Set my working directory to where some data are stored\nsetwd(\"/mnt/code/gsk_R_training/data\")\n\nIn the example below we import data that is located in our current working directory. We can therefore simply specify the name of the file (including the extension) and ignore the path.\n\ndm &lt;- read_sas(\"dm.sas7bdat\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#projects",
    "href": "05_importing_and_exporting_data.html#projects",
    "title": "5  Importing/Exporting Data",
    "section": "5.5 Projects",
    "text": "5.5 Projects\nWe started this course by creating an RStudio project. One of the benefits of creating a project within a directory is that it sets the workspace to that directory. This means that we can immediately use relative file paths for any local data.\nFor more information on RStudio projects see [RStudio Projects]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#data-on-shared-drives",
    "href": "05_importing_and_exporting_data.html#data-on-shared-drives",
    "title": "5  Importing/Exporting Data",
    "section": "5.6 Data on Shared Drives",
    "text": "5.6 Data on Shared Drives\nIt is generally considered good practice to maintain a single source of truth for our data. Where possible we should avoid making local copies. Instead, we can create an alias for a remote location, similar to the SAS ‘libname’ approach. The simplest way to do this is to save the path to the data directory as an object and use the file.path function to specify the specific datasets we want to read in. The file.path function concatenates text using \"/\".\n\n# I have SAS files here:\nsdtm &lt;- \"/mnt/code/gsk_R_training/data\"\n\n# Now I want to read in data\ndm &lt;- read_sas( file.path(sdtm, \"dm.sas7bdat\") )\n\nNote: For details on connecting to common data repositories such as the HARP file share, LSAF, RDIP, GDrive and Denodo, see the WARP Data Backends user guide",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#import",
    "href": "05_importing_and_exporting_data.html#import",
    "title": "5  Importing/Exporting Data",
    "section": "5.7 EXERCISE",
    "text": "5.7 EXERCISE\n\nImport the theoph data into R using a relative file path (i.e. one that starts “data/”)\n\nCheck that it has imported correctly - how many rows and columns does it have?\n\nImport the act data into R\n\nCheck that it has imported correctly - how many rows and columns does it have?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "05_importing_and_exporting_data.html#exporting-data",
    "href": "05_importing_and_exporting_data.html#exporting-data",
    "title": "5  Importing/Exporting Data",
    "section": "5.8 Exporting Data",
    "text": "5.8 Exporting Data\nThere is an experimental, write_sas function within haven. However it is not currently possible to export data to the “.SAS7BDAT” format with any consistency. However we may export data by using the haven function write_xpt to the “.XPT” (a.k.a. “SAS transport file”) format following the SAS V5 standard (acceptable for submission to regulatory agencies).\nIn addition, we may export data to various delimited file formats … using readr functions such as write_delim or write_csv. The format of such functions is extremely consistent - the first argument is the name of the data (i.e. the R object name) and the second argument is the name of the file that we wish to write to. Here is an example using write_csv.\n\nwrite_csv(dm, \"dm.csv\")\n\nOther useful arguments to write_csv include na, which controls the way missing values are written to the output file (defaults to \"NA\"), and append which, when set to TRUE allows us to append to existing files rather than create new ones or overwrite existing files.\n\nwrite_csv(dm, \"dm_saslike.csv\", na = \".\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importing/Exporting Data</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html",
    "href": "06_basic_data_processing.html",
    "title": "6  Data Handling",
    "section": "",
    "text": "6.1 Subsetting Rows: filter\nOne of the fundamental building blocks of the tidyverse is the dplyr package. The dplyr package is now the primary package for data manipulation in R. Each of the functions that we look at in this chapter take a data frame as the first input argument, process it in a very simple way and return a data frame as the output. The dplyr package is loaded by default when we load the tidyverse package but we can also load it independently.\nIn accordance with the tidyverse spirit of functions doing one thing and doing it well, there are separate functions for subsetting rows and for subsetting columns.\nThe filter function allows us to apply a logical subset to the rows of our data. As with all the dplyr functions that we will use in this course, the filter function takes a data frame as the first argument and a logical statement as the second argument. Typically, we base the logical statement on columns within our data frame.\nlibrary(ggplot2)\ndm &lt;- haven::read_sas(\"data/dm.sas7bdat\")\nact &lt;- haven::read_sas(\"data/act.sas7bdat\")\nvs &lt;- haven::read_sas(\"data/vs.sas7bdat\")\n# Find subjects taking GSK drug.  Note the double-equals\ngsk_subj &lt;- filter(dm, ARM == \"GSK\")\ngsk_subj\n\n# A tibble: 12 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 2 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n 3 STD123456:000011    66 F     USA     WHITE                     NOT HIS… GSK  \n 4 STD123456:000012    26 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… GSK  \n 5 STD123456:000013    51 F     IRE     WHITE                     HISPANI… GSK  \n 6 STD123456:000015    59 F     FRA     WHITE                     HISPANI… GSK  \n 7 STD123456:000017    28 F     FRA     WHITE                     NOT HIS… GSK  \n 8 STD123456:000019    48 F     USA     WHITE                     NOT HIS… GSK  \n 9 STD123456:000022    46 M     GER     WHITE                     NOT HIS… GSK  \n10 STD123456:000025    48 F     USA     WHITE                     NOT HIS… GSK  \n11 STD123456:000026    71 F     FRA     WHITE                     NOT HIS… GSK  \n12 STD123456:000028    67 M     IRE     WHITE                     HISPANI… GSK",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#subsetting-rows-filter",
    "href": "06_basic_data_processing.html#subsetting-rows-filter",
    "title": "6  Data Handling",
    "section": "",
    "text": "6.1.1 Logic\nIn the example above we used a double equals in order to ask the question, “is the ARM variable equal to ‘GSK’ (for each record)?” In R a single equals assigns the value on the right to the parameter on the left. We must therefore always use a double equals when asking the logical question, is x equal to y!!!\nThe table below lists some essential logical operations.\n\n\n\n\n\n\n\n\n\nCode\nMeaning\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n&gt;\nGreater than\n\n\n&gt;=\nGreater than or equal to\n\n\n&lt;\nLess than\n\n\n&lt;=\nLess than or equal to\n\n\n&\nAnd - for joining logical statements\n\n\n|\nOr - for joining locical statements\n\n\n!\nNot - for switching TRUE and FALSE statements around\n\n\n%in%\nOne of - Can any of the values on the LHS of the %in% be found on the RHS?\n\n\nany\nSummarises multiple logical statements into a single value - Are ANY of these values equal to TRUE?\n\n\nall\nSummarises multiple logical statements into a single value - Are ALL of these values equal to TRUE?\n\n\n\n\n\n\n\n6.1.2 Applying Multiple filter Operations\nThe filter function let’s us chain multiple logical questions together using commas. The commas are equivalent to using an “and” operation.\n\n# Find subjects taking GSK drug in USA\ngsk_subj_USA &lt;- filter(dm, ARM == \"GSK\", COUNTRY == \"USA\")\ngsk_subj_USA\n\n# A tibble: 4 × 7\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC                 ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;\n1 STD123456:000009    60 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n2 STD123456:000011    66 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n3 STD123456:000019    48 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n4 STD123456:000025    48 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n\n# Or equivalently\ngsk_subj_USA &lt;- filter(dm, ARM == \"GSK\" & COUNTRY == \"USA\")\n\nThe following example uses an “or” link.\n\n# Find females over 50 in France or Germany\nfilter(dm, SEX==\"F\", AGE &gt; 50, COUNTRY == \"FRA\" | COUNTRY == \"GER\")\n\n# A tibble: 2 × 7\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC                 ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;\n1 STD123456:000015    59 F     FRA     WHITE HISPANIC OR LATINO     GSK  \n2 STD123456:000026    71 F     FRA     WHITE NOT HISPANIC OR LATINO GSK  \n\n\nFinally, here is an example using the %in% operator. Although it looks a little ugly, this function is the same as an “in” in SQL or SAS. In other words “are any of the values on the left hand side contained within the values on the right hand side”?\n\n# Find females over 50 in France or Germany\nfilter(dm, SEX==\"F\", AGE &gt; 50, COUNTRY %in% c(\"FRA\", \"GER\"))\n\n# A tibble: 2 × 7\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC                 ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;\n1 STD123456:000015    59 F     FRA     WHITE HISPANIC OR LATINO     GSK  \n2 STD123456:000026    71 F     FRA     WHITE NOT HISPANIC OR LATINO GSK  \n\n\n\n\n6.1.3 Any and All\nThe any and all functions condense any number of logical values into a single TRUE or FALSE value. At this stage of the course they are not much use but we will look at them a little closer later on.\n\n# Some logical values\nsome_logic &lt;- c(T, T, F)\nsome_logic\n\n[1]  TRUE  TRUE FALSE\n\n# Are any of these values TRUE?\nany(some_logic)\n\n[1] TRUE\n\n# Excellent.  Are they all TRUE?\nall(some_logic)\n\n[1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#extract-rows-by-number-slice",
    "href": "06_basic_data_processing.html#extract-rows-by-number-slice",
    "title": "6  Data Handling",
    "section": "6.2 Extract Rows by Number: slice",
    "text": "6.2 Extract Rows by Number: slice\nThe slice function lets us choose records by row number. It can be useful for looking at the first or last few records in a data frame. In the second example below the utility function, n, is used to pick out the last few rows. This utility is not a generic utility and can only be used within a handful of dplyr functions.\n\n# First 3 rows of dm\nslice(dm, 1:3)\n\n# A tibble: 3 × 7\n  USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC    ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;\n1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HISP… Comp…\n2 STD123456:000002    28 M     FRA     WHITE                     NOT HISP… Comp…\n3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HISP… Comp…\n\n# Last 3 rows of dm (using the utility function, n())\nslice(dm, (n() - 2):n())\n\n# A tibble: 3 × 7\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC                 ARM       \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;     \n1 STD123456:000028    67 M     IRE     WHITE HISPANIC OR LATINO     GSK       \n2 STD123456:000029    68 F     UK      WHITE NOT HISPANIC OR LATINO Comparator\n3 STD123456:000030    71 M     USA     WHITE NOT HISPANIC OR LATINO Comparator",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#removing-duplicates-distinct",
    "href": "06_basic_data_processing.html#removing-duplicates-distinct",
    "title": "6  Data Handling",
    "section": "6.3 Removing Duplicates: distinct",
    "text": "6.3 Removing Duplicates: distinct\nWe can often find ourselves in a situation where we end up with duplicate or partial duplicates, eg following a merge. The distinct function is a useful utility that can help us to identify unique values and/or remove duplicates.\n\n# Duplicate records\ndup_data &lt;- tibble(USUBJID = rep(c(\"STD123456:000001\", \"STD123456:000002\"), c(3, 5)),\n                   AGE = rep(c(32, 28), c(3, 5)))\ndup_data\n\n# A tibble: 8 × 2\n  USUBJID            AGE\n  &lt;chr&gt;            &lt;dbl&gt;\n1 STD123456:000001    32\n2 STD123456:000001    32\n3 STD123456:000001    32\n4 STD123456:000002    28\n5 STD123456:000002    28\n6 STD123456:000002    28\n7 STD123456:000002    28\n8 STD123456:000002    28\n\n# Remove duplicate records\ndistinct(dup_data)\n\n# A tibble: 2 × 2\n  USUBJID            AGE\n  &lt;chr&gt;            &lt;dbl&gt;\n1 STD123456:000001    32\n2 STD123456:000002    28\n\n\nWe can also use distinct to find all the unique combinations of specific variables. For example the unique combinations of ‘COUNTRY’ and ‘ARM’. By default, the function drops all of the other variables that we’re not interested. But we can also choose to keep them. In the example below, this retains the first record for each unique combination of ‘COUNTRY’ and ‘ARM’, which is not particularly useful. But it could be used to identify baseline records for each unique subject.\n\n# Find unique combinations\ndistinct(dm, COUNTRY, ARM)\n\n# A tibble: 9 × 2\n  COUNTRY ARM       \n  &lt;chr&gt;   &lt;chr&gt;     \n1 UK      Comparator\n2 FRA     Comparator\n3 USA     Comparator\n4 GER     Comparator\n5 IRE     Comparator\n6 GER     GSK       \n7 USA     GSK       \n8 FRA     GSK       \n9 IRE     GSK       \n\n# Find unique combinations and keep the first instance of each\ndistinct(dm, COUNTRY, ARM, .keep_all = TRUE)\n\n# A tibble: 9 × 7\n  USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC    ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;\n1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HISP… Comp…\n2 STD123456:000002    28 M     FRA     WHITE                     NOT HISP… Comp…\n3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HISP… Comp…\n4 STD123456:000004    35 F     GER     WHITE                     HISPANIC… Comp…\n5 STD123456:000005    30 F     IRE     WHITE                     NOT HISP… Comp…\n6 STD123456:000008    53 M     GER     WHITE                     NOT HISP… GSK  \n7 STD123456:000009    60 F     USA     WHITE                     NOT HISP… GSK  \n8 STD123456:000012    26 M     FRA     BLACK OR AFRICAN AMERICAN NOT HISP… GSK  \n9 STD123456:000013    51 F     IRE     WHITE                     HISPANIC… GSK",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#subsetting-columns-select",
    "href": "06_basic_data_processing.html#subsetting-columns-select",
    "title": "6  Data Handling",
    "section": "6.4 Subsetting Columns: select",
    "text": "6.4 Subsetting Columns: select\nFor column-wise operations we use the select function. Much like when writing SQL, we simply provide the function a data frame to select columns from and then a bunch of columns that we wish to select (or “keep”).\n\n# Our GSK, USA Subjects from earlier\ngsk_subj_USA\n\n# A tibble: 4 × 7\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC                 ARM  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;\n1 STD123456:000009    60 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n2 STD123456:000011    66 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n3 STD123456:000019    48 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n4 STD123456:000025    48 F     USA     WHITE NOT HISPANIC OR LATINO GSK  \n\n# Now that we have GSK subjects in USA we don't need ARM or COUNTRY\nselect(gsk_subj_USA, USUBJID, AGE, SEX)\n\n# A tibble: 4 × 3\n  USUBJID            AGE SEX  \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;\n1 STD123456:000009    60 F    \n2 STD123456:000011    66 F    \n3 STD123456:000019    48 F    \n4 STD123456:000025    48 F    \n\n\nWe can also use the select function to drop columns by putting a minus sign in front of any columns that we provide.\n\n# Now that we have GSK subjects in USA we don't need ARM or COUNTRY\nselect(gsk_subj_USA, -ARM, -COUNTRY)\n\n# A tibble: 4 × 5\n  USUBJID            AGE SEX   RACE  ETHNIC                \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;                 \n1 STD123456:000009    60 F     WHITE NOT HISPANIC OR LATINO\n2 STD123456:000011    66 F     WHITE NOT HISPANIC OR LATINO\n3 STD123456:000019    48 F     WHITE NOT HISPANIC OR LATINO\n4 STD123456:000025    48 F     WHITE NOT HISPANIC OR LATINO\n\n\nObviously we cannot mix and match dropping and keeping variables.\n\n6.4.1 Utility Functions in Select\nThe select function comes with a number of built in utility functions (the tidy-select functions, ?dplyr_tidy_select). The functions are there to enable us to select columns more quickly, for example all of the columns that contain a particular word. These functions can only be called from within select and a handful of other tidyverse functions. They cannot be called directly.\n\nstarts_with\nends_with\ncontains\nmatches\none_of\neverything\n…\n\nTo use these utility functions we simply call them in place of a named column(s). For example, here we select all columns that begin with the letters “ACT”:\n\nselect(act, starts_with(\"ACT\"))\n\n# A tibble: 165 × 5\n   ACT0101 ACT0102 ACT0103 ACT0104 ACT0105\n     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1       5       2       3       3       3\n 2       5       2       3       3       3\n 3       3       4       3       2       1\n 4       3       3       4       3       2\n 5       3       5       1       2       3\n 6       3       5       3       3       3\n 7       3       3       3       3       3\n 8       3       3       3       3       3\n 9       3       3       3       4       4\n10       4       4       4       4       4\n# ℹ 155 more rows\n\n\nWe can also use a : to select all columns between the column on the left of the : and the column on the right of the :.\n\nselect(dm, AGE:COUNTRY)\n\n# A tibble: 30 × 3\n     AGE SEX   COUNTRY\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1    32 F     UK     \n 2    28 M     FRA    \n 3    55 M     USA    \n 4    35 F     GER    \n 5    30 F     IRE    \n 6    22 F     GER    \n 7    59 F     USA    \n 8    53 M     GER    \n 9    60 F     USA    \n10    48 M     USA    \n# ℹ 20 more rows\n\n\nIt is again important to note that although : can be used outside of the select function, the way we have used it to specify columns is unique to this use case. In other words we can’t write “A”:“Z” or similar.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#column-order",
    "href": "06_basic_data_processing.html#column-order",
    "title": "6  Data Handling",
    "section": "6.5 Column Order",
    "text": "6.5 Column Order\nAs well as subsetting columns, we can use select to move columns around (e.g. after a merge). Here we use the everything helper to move the ‘ARM’ column to the left and then keep ‘everything else’ as it was.\n\nselect(dm, ARM, everything())\n\n# A tibble: 30 × 7\n   ARM        USUBJID            AGE SEX   COUNTRY RACE                   ETHNIC\n   &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                  &lt;chr&gt; \n 1 Comparator STD123456:000001    32 F     UK      BLACK OR AFRICAN AMER… NOT H…\n 2 Comparator STD123456:000002    28 M     FRA     WHITE                  NOT H…\n 3 Comparator STD123456:000003    55 M     USA     BLACK OR AFRICAN AMER… NOT H…\n 4 Comparator STD123456:000004    35 F     GER     WHITE                  HISPA…\n 5 Comparator STD123456:000005    30 F     IRE     WHITE                  NOT H…\n 6 Comparator STD123456:000006    22 F     GER     WHITE                  NOT H…\n 7 Comparator STD123456:000007    59 F     USA     WHITE                  NOT H…\n 8 GSK        STD123456:000008    53 M     GER     WHITE                  NOT H…\n 9 GSK        STD123456:000009    60 F     USA     WHITE                  NOT H…\n10 Comparator STD123456:000010    48 M     USA     WHITE                  NOT H…\n# ℹ 20 more rows\n\n\nThe relocate function is another relatively recent addition to dplyr that provides finer control when moving columns. Arguments .before and .after let us specify exactly where one or more columns are to be located.\n\nrelocate(dm, ARM, .after = USUBJID)\n\n# A tibble: 30 × 7\n   USUBJID          ARM          AGE SEX   COUNTRY RACE                   ETHNIC\n   &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                  &lt;chr&gt; \n 1 STD123456:000001 Comparator    32 F     UK      BLACK OR AFRICAN AMER… NOT H…\n 2 STD123456:000002 Comparator    28 M     FRA     WHITE                  NOT H…\n 3 STD123456:000003 Comparator    55 M     USA     BLACK OR AFRICAN AMER… NOT H…\n 4 STD123456:000004 Comparator    35 F     GER     WHITE                  HISPA…\n 5 STD123456:000005 Comparator    30 F     IRE     WHITE                  NOT H…\n 6 STD123456:000006 Comparator    22 F     GER     WHITE                  NOT H…\n 7 STD123456:000007 Comparator    59 F     USA     WHITE                  NOT H…\n 8 STD123456:000008 GSK           53 M     GER     WHITE                  NOT H…\n 9 STD123456:000009 GSK           60 F     USA     WHITE                  NOT H…\n10 STD123456:000010 Comparator    48 M     USA     WHITE                  NOT H…\n# ℹ 20 more rows\n\n# Alternatively\n#relocate(dm, AGE:COUNTRY, .after = ARM)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#sorting",
    "href": "06_basic_data_processing.html#sorting",
    "title": "6  Data Handling",
    "section": "6.6 Sorting",
    "text": "6.6 Sorting\nIn general, tidyverse functions are named well and hence easy to remember. Unfortunately, sort and order already exist as R functions and so in the tidyverse we work with arrange! As with most of the tidyverse functions it is very easy to use. In this first example we use the arrange function to sort the demography data by age.\n\n# Sort young to old\narrange(dm, AGE)\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 2 STD123456:000012    26 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… GSK  \n 3 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 4 STD123456:000017    28 F     FRA     WHITE                     NOT HIS… GSK  \n 5 STD123456:000023    28 F     IRE     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 6 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 7 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 8 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 9 STD123456:000022    46 M     GER     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n\nFor a descending sort we call the utility function, desc, around the variable that we’re sorting by.\n\n# Sort old to young\narrange(dm, desc(AGE))\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000026    71 F     FRA     WHITE                     NOT HIS… GSK  \n 2 STD123456:000030    71 M     USA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000018    69 F     IRE     WHITE                     NOT HIS… Comp…\n 4 STD123456:000029    68 F     UK      WHITE                     NOT HIS… Comp…\n 5 STD123456:000027    67 F     IRE     ASIAN                     NOT HIS… Comp…\n 6 STD123456:000028    67 M     IRE     WHITE                     HISPANI… GSK  \n 7 STD123456:000011    66 F     USA     WHITE                     NOT HIS… GSK  \n 8 STD123456:000020    64 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n\nWe can sort by as many variables as we have in our data. We can also sort by categorical variables, which are ordered alphabetically in the sort.\n\n# Sort by multiple variables\narrange(dm, desc(ARM), COUNTRY, desc(AGE))\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000026    71 F     FRA     WHITE                     NOT HIS… GSK  \n 2 STD123456:000015    59 F     FRA     WHITE                     HISPANI… GSK  \n 3 STD123456:000017    28 F     FRA     WHITE                     NOT HIS… GSK  \n 4 STD123456:000012    26 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… GSK  \n 5 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 6 STD123456:000022    46 M     GER     WHITE                     NOT HIS… GSK  \n 7 STD123456:000028    67 M     IRE     WHITE                     HISPANI… GSK  \n 8 STD123456:000013    51 F     IRE     WHITE                     HISPANI… GSK  \n 9 STD123456:000011    66 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n# ℹ 20 more rows\n\n\nLater we will see how we can manipulate the sort order for categorical variables using factors.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#subsetting",
    "href": "06_basic_data_processing.html#subsetting",
    "title": "6  Data Handling",
    "section": "6.7 EXERCISE",
    "text": "6.7 EXERCISE\n\nUsing the act data, extract all data for subject 5\nExtract all screening and randomisation visits from the act data\nSelect the USUBJID, VISITNUM and VISIT columns\nRemove the date (QSDTC) column\nSort the data by USUBJID and descending VISITNUM",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#creating-new-columns-mutate",
    "href": "06_basic_data_processing.html#creating-new-columns-mutate",
    "title": "6  Data Handling",
    "section": "6.8 Creating New Columns: mutate",
    "text": "6.8 Creating New Columns: mutate\nThe mutate function allows us to create new columns within our data. We typically do so by manipulating other columns in the data but we can define our columns in any way we like.\n\n# Create a new column that is the square of the height column\nmutate(vs, Height_sq = HEIGHT ^2)\n\n# A tibble: 30 × 4\n   USUBJID          HEIGHT WEIGHT Height_sq\n   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 STD123456:000001    165   88       27225\n 2 STD123456:000002    179  100       32041\n 3 STD123456:000003    182   81       33124\n 4 STD123456:000004    166   91       27556\n 5 STD123456:000005    169   73.6     28561\n 6 STD123456:000006    164   66       26896\n 7 STD123456:000007    157  107       24649\n 8 STD123456:000008    189  101       35721\n 9 STD123456:000009    155   54.1     24025\n10 STD123456:000010    171   88       29241\n# ℹ 20 more rows\n\n# Create a new flag variable with the value 1\nmutate(vs, flag = 1)\n\n# A tibble: 30 × 4\n   USUBJID          HEIGHT WEIGHT  flag\n   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 STD123456:000001    165   88       1\n 2 STD123456:000002    179  100       1\n 3 STD123456:000003    182   81       1\n 4 STD123456:000004    166   91       1\n 5 STD123456:000005    169   73.6     1\n 6 STD123456:000006    164   66       1\n 7 STD123456:000007    157  107       1\n 8 STD123456:000008    189  101       1\n 9 STD123456:000009    155   54.1     1\n10 STD123456:000010    171   88       1\n# ℹ 20 more rows\n\n\nOne nice property of the mutate function is that it allows us to immediately use columns that we create, much like SAS.\n\nmutate(vs, \n       Height_m2 = (HEIGHT/100) ^2, \n       BMI = WEIGHT / Height_m2)\n\n# A tibble: 30 × 5\n   USUBJID          HEIGHT WEIGHT Height_m2   BMI\n   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 STD123456:000001    165   88        2.72  32.3\n 2 STD123456:000002    179  100        3.20  31.2\n 3 STD123456:000003    182   81        3.31  24.5\n 4 STD123456:000004    166   91        2.76  33.0\n 5 STD123456:000005    169   73.6      2.86  25.8\n 6 STD123456:000006    164   66        2.69  24.5\n 7 STD123456:000007    157  107        2.46  43.4\n 8 STD123456:000008    189  101        3.57  28.3\n 9 STD123456:000009    155   54.1      2.40  22.5\n10 STD123456:000010    171   88        2.92  30.1\n# ℹ 20 more rows\n\n\nIn the above example we have used some very simple numerical transformations. In the following sections we will look at some other useful functions for working with data. Each of the functions that we see are designed to work with vectors (columns of data). We can therefore call them all via the mutate function.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#renaming-columns",
    "href": "06_basic_data_processing.html#renaming-columns",
    "title": "6  Data Handling",
    "section": "6.9 Renaming Columns",
    "text": "6.9 Renaming Columns\nIn the example below we rename the “COUNTRY” column, “LOCATION”. As we shall see later when creating new columns, the new name of the new column is placed to the left of the equals and the old name on the right.\n\n# Rename the COUNTRY column to LOCATION - New name on the left!!!\nrename(dm, LOCATION = COUNTRY)\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   LOCATION RACE                      ETHNIC  ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt;\n 1 STD123456:000001    32 F     UK       BLACK OR AFRICAN AMERICAN NOT HI… Comp…\n 2 STD123456:000002    28 M     FRA      WHITE                     NOT HI… Comp…\n 3 STD123456:000003    55 M     USA      BLACK OR AFRICAN AMERICAN NOT HI… Comp…\n 4 STD123456:000004    35 F     GER      WHITE                     HISPAN… Comp…\n 5 STD123456:000005    30 F     IRE      WHITE                     NOT HI… Comp…\n 6 STD123456:000006    22 F     GER      WHITE                     NOT HI… Comp…\n 7 STD123456:000007    59 F     USA      WHITE                     NOT HI… Comp…\n 8 STD123456:000008    53 M     GER      WHITE                     NOT HI… GSK  \n 9 STD123456:000009    60 F     USA      WHITE                     NOT HI… GSK  \n10 STD123456:000010    48 M     USA      WHITE                     NOT HI… Comp…\n# ℹ 20 more rows\n\n\nFurther columns can be renamed by using a comma to separate each pair of new and old names.\n\n# Rename two columns - New name on the left!!!\nrename(dm, LOCATION = COUNTRY, TREATMENT = ARM)\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   LOCATION RACE                   ETHNIC TREATMENT\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;    \n 1 STD123456:000001    32 F     UK       BLACK OR AFRICAN AMER… NOT H… Comparat…\n 2 STD123456:000002    28 M     FRA      WHITE                  NOT H… Comparat…\n 3 STD123456:000003    55 M     USA      BLACK OR AFRICAN AMER… NOT H… Comparat…\n 4 STD123456:000004    35 F     GER      WHITE                  HISPA… Comparat…\n 5 STD123456:000005    30 F     IRE      WHITE                  NOT H… Comparat…\n 6 STD123456:000006    22 F     GER      WHITE                  NOT H… Comparat…\n 7 STD123456:000007    59 F     USA      WHITE                  NOT H… Comparat…\n 8 STD123456:000008    53 M     GER      WHITE                  NOT H… GSK      \n 9 STD123456:000009    60 F     USA      WHITE                  NOT H… GSK      \n10 STD123456:000010    48 M     USA      WHITE                  NOT H… Comparat…\n# ℹ 20 more rows",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#creating-categories-cut",
    "href": "06_basic_data_processing.html#creating-categories-cut",
    "title": "6  Data Handling",
    "section": "6.10 Creating Categories: cut",
    "text": "6.10 Creating Categories: cut\nThe cut function allows us to create a discrete variable by partitioning a continuous one. The first argument to the function is the continuous vector/variable that we wish to partition. We must then either specify a number of cut points (and let R choose the cuts for us) or provide a vector of specific cut points (including minimum and maximum values). For example, here we divide the AGE variable into two groups, 18-50 and 50+.\n\n# Extract the AGE column as a vector (not required if using mutate!)\nAGE &lt;- pull(dm, AGE)\n# Partition into two groups\ncut(AGE, c(18, 50, Inf))\n\n [1] (18,50]  (18,50]  (50,Inf] (18,50]  (18,50]  (18,50]  (50,Inf] (50,Inf]\n [9] (50,Inf] (18,50]  (50,Inf] (18,50]  (50,Inf] (18,50]  (50,Inf] (50,Inf]\n[17] (18,50]  (50,Inf] (18,50]  (50,Inf] (50,Inf] (18,50]  (18,50]  (18,50] \n[25] (18,50]  (50,Inf] (50,Inf] (50,Inf] (50,Inf] (50,Inf]\nLevels: (18,50] (50,Inf]\n\n\nBy default, any data points lying on the boundary are included in the lower grouping. This is controlled by an argument to the cut function, right. If we want to include boundary values to be included in the higher grouping we set right = FALSE.\n\n# Include 50 years olds in the older group\nage_cat &lt;- cut(AGE, c(18, 50, Inf), right = FALSE)\nage_cat\n\n [1] [18,50)  [18,50)  [50,Inf) [18,50)  [18,50)  [18,50)  [50,Inf) [50,Inf)\n [9] [50,Inf) [18,50)  [50,Inf) [18,50)  [50,Inf) [18,50)  [50,Inf) [50,Inf)\n[17] [18,50)  [50,Inf) [18,50)  [50,Inf) [50,Inf) [18,50)  [18,50)  [50,Inf)\n[25] [18,50)  [50,Inf) [50,Inf) [50,Inf) [50,Inf) [50,Inf)\nLevels: [18,50) [50,Inf)\n\n\nWe can add nicer labels to our cut by using the labels argument.\n\naround50 &lt;- filter(dm, 48 &lt;= AGE, AGE &lt;= 52)\nmutate(around50, \n       AgeCat1 = cut(AGE, c(18, 50, Inf), labels = c(\"&lt;=50\", \"&gt;50\")),\n       AgeCat2 = cut(AGE, c(18, 50, Inf), labels = c(\"&lt;50\", \"&gt;=50\"), \n                     right = FALSE)) \n\n# A tibble: 6 × 9\n  USUBJID            AGE SEX   COUNTRY RACE  ETHNIC        ARM   AgeCat1 AgeCat2\n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt; &lt;fct&gt;   &lt;fct&gt;  \n1 STD123456:000010    48 M     USA     WHITE NOT HISPANIC… Comp… &lt;=50    &lt;50    \n2 STD123456:000013    51 F     IRE     WHITE HISPANIC OR … GSK   &gt;50     &gt;=50   \n3 STD123456:000014    48 F     USA     WHITE HISPANIC OR … Comp… &lt;=50    &lt;50    \n4 STD123456:000019    48 F     USA     WHITE NOT HISPANIC… GSK   &lt;=50    &lt;50    \n5 STD123456:000024    50 F     FRA     WHITE NOT HISPANIC… Comp… &lt;=50    &gt;=50   \n6 STD123456:000025    48 F     USA     WHITE NOT HISPANIC… GSK   &lt;=50    &lt;50",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#factors-and-the-forcats-package",
    "href": "06_basic_data_processing.html#factors-and-the-forcats-package",
    "title": "6  Data Handling",
    "section": "6.11 Factors and the forcats Package",
    "text": "6.11 Factors and the forcats Package\nThe cut function turns a continuous variable into a categorical variable by creating a “factor”. Factors are essentially a code-decode paring where the code is an integer value from 1 to the number of levels, and the decode is a format that controls how these decodes are displayed. We can turn any variable into a factor by using the factor function. Factor variables are displayed as &lt;fctr&gt; when printing a data frame.\n\n# Extract the SEX column and convert to a factor\nSEX &lt;- pull(dm, SEX)\nSEX &lt;- factor(SEX)\nSEX\n\n [1] F M M F F F F M F M F M F F F F F F F M M M F F F F F M F M\nLevels: F M\n\n\n\n6.11.1 The forcats Package\nCreating a factors is easy, but the real benefit comes from being able to manipulate the factor “levels” in order to either control the sort order or to combine levels. All of the required functionality is contained within the forcats package. We start by loading the package, which is installed with the tidyverse but which must always be loaded separately.\n\n# Relabel F and M\nlibrary(forcats)\n# What is in the package?\nobjects(\"package:forcats\")\n\n [1] \"%&gt;%\"                   \"as_factor\"             \"fct\"                  \n [4] \"fct_anon\"              \"fct_c\"                 \"fct_collapse\"         \n [7] \"fct_count\"             \"fct_cross\"             \"fct_drop\"             \n[10] \"fct_expand\"            \"fct_explicit_na\"       \"fct_infreq\"           \n[13] \"fct_inorder\"           \"fct_inseq\"             \"fct_lump\"             \n[16] \"fct_lump_lowfreq\"      \"fct_lump_min\"          \"fct_lump_n\"           \n[19] \"fct_lump_prop\"         \"fct_match\"             \"fct_na_level_to_value\"\n[22] \"fct_na_value_to_level\" \"fct_other\"             \"fct_recode\"           \n[25] \"fct_relabel\"           \"fct_relevel\"           \"fct_reorder\"          \n[28] \"fct_reorder2\"          \"fct_rev\"               \"fct_shift\"            \n[31] \"fct_shuffle\"           \"fct_unify\"             \"fct_unique\"           \n[34] \"first2\"                \"gss_cat\"               \"last2\"                \n[37] \"lvls_expand\"           \"lvls_reorder\"          \"lvls_revalue\"         \n[40] \"lvls_union\"           \n\n\n\n\n6.11.2 Reordering Levels\nHaving created a factor we can use the lvls_reorder function to change the order of the factor levels. In our earlier example we created a factor from the SEX column in dm. By default, factors are ordered alphabetically and so females have the value 1 underneath and males have the value 2. To use the lvls_reorder function we specify the name of the factor that we wish to re-order, then the order of the levels.\n\n# What is the current order?\nSEX\n\n [1] F M M F F F F M F M F M F F F F F F F M M M F F F F F M F M\nLevels: F M\n\n# Re-order females and males\nSEX &lt;- lvls_reorder(SEX, c(2, 1))\nSEX\n\n [1] F M M F F F F M F M F M F F F F F F F M M M F F F F F M F M\nLevels: M F\n\n# Now in the data, (where we can't see the order unless we sort)\ndm_new &lt;- mutate(dm, SEX = lvls_reorder(SEX, c(2, 1)))\narrange(dm_new, SEX)\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 2 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 3 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 4 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n 5 STD123456:000012    26 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… GSK  \n 6 STD123456:000020    64 M     FRA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 7 STD123456:000021    55 M     GER     ASIAN                     NOT HIS… Comp…\n 8 STD123456:000022    46 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000028    67 M     IRE     WHITE                     HISPANI… GSK  \n10 STD123456:000030    71 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n\nNote that in order to use the lvls_reorder successfully we need to be certain of the current order of the levels. As a more sophisticated alternative we can also reorder the levels of one variable based on the values of another using the fct_reorder function. This is particularly useful for plotting.\n\n# Generate some fake count data of favourite colours\ncolour_data &lt;- tibble(Colour = c(\"red\", \"green\", \"blue\"),\n                     Count = c(8, 28, 19))\n\n# Create a factor of the Colour column and order by the (descending) Count\n# I.e. highest count first\nnew_colour_data &lt;- mutate(\n  colour_data,\n  Colour_order = fct_reorder(Colour, Count, .desc = TRUE))\n\n# Plot the data using ggplot2\nggplot(data = new_colour_data) +\n  geom_bar(aes(x = Colour_order, y = Count), stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\n6.11.3 Recoding Factors (Changing the Labels)\nWe can change the labels in a simple way using the lvls_revalue function. To use the lvls_revalue function we provide the factor that we wish to re-label and a vector of new labels. It is once again important that we know the current order of levels when using the lvls_revalue function. To be more specific about the recoding we can use the fct_recode function.\n\n# Extract the data\nSEX &lt;- pull(dm, SEX)\nSEX\n\n [1] \"F\" \"M\" \"M\" \"F\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"F\" \"F\" \"F\" \"F\" \"F\" \"F\"\n[20] \"M\" \"M\" \"M\" \"F\" \"F\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\"\nattr(,\"label\")\n[1] \"Sex\"\n\n# Relabel F and M to Female and Male\nSEX_lab &lt;- lvls_revalue(SEX, c(\"Female\", \"Male\"))\nSEX_lab\n\n [1] Female Male   Male   Female Female Female Female Male   Female Male  \n[11] Female Male   Female Female Female Female Female Female Female Male  \n[21] Male   Male   Female Female Female Female Female Male   Female Male  \nLevels: Female Male\n\n# Alternatively we may take this more robust approach\nSEX_lab &lt;- fct_recode(SEX, Female = \"F\", Male = \"M\")\nSEX_lab\n\n [1] Female Male   Male   Female Female Female Female Male   Female Male  \n[11] Female Male   Female Female Female Female Female Female Female Male  \n[21] Male   Male   Female Female Female Female Female Male   Female Male  \nLevels: Female Male\n\n\n\n\n6.11.4 Collapsing/Combining Levels\nThe fct_recode can also be used to combine levels and re-classify a variable. In the example below we combine the European nations in the dm data by recoding each to \"Europe\".\n\n# Extratc COUNTRY coloumn\nCOUNTRY &lt;- pull(dm, COUNTRY)\nCOUNTRY\n\n [1] \"UK\"  \"FRA\" \"USA\" \"GER\" \"IRE\" \"GER\" \"USA\" \"GER\" \"USA\" \"USA\" \"USA\" \"FRA\"\n[13] \"IRE\" \"USA\" \"FRA\" \"USA\" \"FRA\" \"IRE\" \"USA\" \"FRA\" \"GER\" \"GER\" \"IRE\" \"FRA\"\n[25] \"USA\" \"FRA\" \"IRE\" \"IRE\" \"UK\"  \"USA\"\nattr(,\"label\")\n[1] \"Country\"\n\n# Create Continent by combining countries\nContinent &lt;- fct_recode(COUNTRY, \n                        Europe = \"UK\", Europe = \"FRA\", \n                        Europe = \"GER\", Europe = \"IRE\")\nContinent\n\n [1] Europe Europe USA    Europe Europe Europe USA    Europe USA    USA   \n[11] USA    Europe Europe USA    Europe USA    Europe Europe USA    Europe\n[21] Europe Europe Europe Europe USA    Europe Europe Europe Europe USA   \nLevels: Europe USA\n\n\nOnce again we have other options available to us when re-classifying a variable. Here is the same example again but using the fct_collapse function. This function allows us to provide a vector of labels to collapse down onto a new label.\n\n# Alternatively\nContinent &lt;- fct_collapse(COUNTRY, Europe = c(\"UK\", \"FRA\", \"GER\", \"IRE\"))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#string-manipulation-with-the-stringr-package",
    "href": "06_basic_data_processing.html#string-manipulation-with-the-stringr-package",
    "title": "6  Data Handling",
    "section": "6.12 String Manipulation with the stringr Package",
    "text": "6.12 String Manipulation with the stringr Package\nThe stringr package, which is part of the tidyverse, provides a whole heap of functions for working with text string. Almost all of the functions in the stringr package (and all of the functions that we look at in this section) begin with the prefix “str_”. Each function takes the text that we’re interested in doing something with as the first argument.\n\n# Load the Package\nlibrary(stringr)\n# What's inside?\nobjects(\"package:stringr\")\n\n [1] \"%&gt;%\"               \"boundary\"          \"coll\"             \n [4] \"fixed\"             \"fruit\"             \"invert_match\"     \n [7] \"regex\"             \"sentences\"         \"str_c\"            \n[10] \"str_conv\"          \"str_count\"         \"str_detect\"       \n[13] \"str_dup\"           \"str_ends\"          \"str_equal\"        \n[16] \"str_escape\"        \"str_extract\"       \"str_extract_all\"  \n[19] \"str_flatten\"       \"str_flatten_comma\" \"str_glue\"         \n[22] \"str_glue_data\"     \"str_ilike\"         \"str_interp\"       \n[25] \"str_length\"        \"str_like\"          \"str_locate\"       \n[28] \"str_locate_all\"    \"str_match\"         \"str_match_all\"    \n[31] \"str_order\"         \"str_pad\"           \"str_rank\"         \n[34] \"str_remove\"        \"str_remove_all\"    \"str_replace\"      \n[37] \"str_replace_all\"   \"str_replace_na\"    \"str_sort\"         \n[40] \"str_split\"         \"str_split_1\"       \"str_split_fixed\"  \n[43] \"str_split_i\"       \"str_squish\"        \"str_starts\"       \n[46] \"str_sub\"           \"str_sub_all\"       \"str_sub&lt;-\"        \n[49] \"str_subset\"        \"str_to_camel\"      \"str_to_kebab\"     \n[52] \"str_to_lower\"      \"str_to_sentence\"   \"str_to_snake\"     \n[55] \"str_to_title\"      \"str_to_upper\"      \"str_trim\"         \n[58] \"str_trunc\"         \"str_unique\"        \"str_view\"         \n[61] \"str_view_all\"      \"str_which\"         \"str_width\"        \n[64] \"str_wrap\"          \"word\"              \"words\"            \n\n\n\n6.12.1 String Length\nLet’s look at a few of the most useful functions, starting with str_length which simply tells us how long a string is. For the examples we work with vectors directly but in practice these functions will most likely be called via the mutate function.\n\nstr_length(\"GSK\")  # equivalenetly `nchar(\"GSK\")`\n\n[1] 3\n\n\n\n\n6.12.2 Adding White Space: Formatting\nWhen producing production outputs we often have to work with white space. The str_pad function adds white space to the left, right or both sides of the given text string depending on what we pass to the side argument. By default the space is added to the left. We add space providing a number, which represents the desired length of each string in the vector.\n\n# Some values that we wish to right align\naes &lt;- c(15, 10, 7, 2, 1, 1)\n\n# Add some padding to the left in order to right align the text\nae_pad &lt;- str_pad(aes, 2)\nae_pad\n\n[1] \"15\" \"10\" \" 7\" \" 2\" \" 1\" \" 1\"\n\n# Or left align for some reason\nstr_pad(aes, 3, side=\"right\")\n\n[1] \"15 \" \"10 \" \"7  \" \"2  \" \"1  \" \"1  \"\n\n\n\n\n6.12.3 Removal of White Space\nWhite space can be useful for formatting but often it just gets in the way, for example of concatenation (see below). As easily as we can add it, we can take it away. We use str_trim (the opposite of str_pad) to remove unwanted space at either end of the string.\n\n# Get rid of the white space that we just added\nstr_trim(ae_pad)\n\n[1] \"15\" \"10\" \"7\"  \"2\"  \"1\"  \"1\" \n\n\n\n\n6.12.4 Concatenation\nThe str_c functions allows us to combine/concatenate string. We simply provide the function with vectors or single pieces of string that we wish to use for the concatenation.\n\n# Calculate percentages and right-align\nae_perc &lt;- round(100*aes / 30)\nae_perc_pad &lt;- str_pad(ae_perc, 2)\n\n# Joing the padded data together for nicely formatted results\nstr_c(ae_pad, \" (\", ae_perc_pad, \"%)\")\n\n[1] \"15 (50%)\" \"10 (33%)\" \" 7 (23%)\" \" 2 ( 7%)\" \" 1 ( 3%)\" \" 1 ( 3%)\"\n\n\n\n\n6.12.5 Paragraphs\nWhen trying to fit lots of text into a confined space it can be useful to wrap when it exceeds some predefined length. The str_wrap function achieves this by strategically placing the return escape, \"\\n\", within the given text.\n\n# Create a paragraph of text\nsome_text &lt;- \"When working in a late phase pharmaceutical environment, it is common to have long titles.  But alas, we must fit these long titles within the limited space offered by the L10 format that we use.  Sad face.\"\n\n# Insert returns in so that it fits within some pre-specified width.\nstr_wrap(some_text, 108) \n\n[1] \"When working in a late phase pharmaceutical environment, it is common to have long titles. But alas, we must\\nfit these long titles within the limited space offered by the L10 format that we use. Sad face.\"\n\n\n\n\n6.12.6 Finding Patterns\nThe stringr package also contains a number of functions that build upon R’s regular expression capabilities. The string functions are similar to others that exist in R but are much more consistent in terms of the order of variables (the string that we’re querying is always the first argument).\nIn the example below we simulate some asthma treatments and find those containing a “LABA” component using the str_detect function.\n\n# Create some asthma treatments\ntreats &lt;- sample(c(\"ICS\", \"ICS/LABA\"), 10, replace = TRUE)\ntreats\n\n [1] \"ICS\"      \"ICS\"      \"ICS\"      \"ICS/LABA\" \"ICS/LABA\" \"ICS\"     \n [7] \"ICS\"      \"ICS/LABA\" \"ICS/LABA\" \"ICS\"     \n\n# Find subjects with LABA component\nstr_detect(treats, \"LABA\")\n\n [1] FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE\n\n\n\n\n6.12.7 Replacing Values\nOnce we’ve found a string pattern we may wish to replace it with something else. The str_replace function allows us to replace one piece of string with another. In order to do so we provide three arguments: the string; the text that we want to find; the text that we want to replace it with when we find it.\n\nstudy_conclusion &lt;- \"The p-value was less than 0.05\"\nstr_replace(study_conclusion, \"less than\", \"greater than\")\n\n[1] \"The p-value was greater than 0.05\"\n\n\nOnce we know what we’re doing we can use the str_replace function to do clever things like replace white space in the middle of a text string.\n\nmessy_text &lt;- c(\"How did    I   end  up with  so   much white           space?\")\n# \"\\\\s+\" searches for cases with any length of white space\nstr_replace_all(messy_text, pattern=\"\\\\s+\", \" \")\n\n[1] \"How did I end up with so much white space?\"",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#mutate",
    "href": "06_basic_data_processing.html#mutate",
    "title": "6  Data Handling",
    "section": "6.13 EXERCISE",
    "text": "6.13 EXERCISE\n\nCreate a new column, ACTTOT, which is the sum of the 5 ACT items in the act data\nCreate a column, ACTRESP, which partitions ACTTOT into “controlled” if ACTTOT &gt;= 20 or “uncontrolled” otherwise.\nCreate a new variable, VISITNew, by formatting the VISITNUM column so that it displays “Screening”, “Randomisation”, “Early Withdrawal” or the appropriate week of the trial, e.g. “Week 6”. HINT: Use the fct_recode function from the forcats package.\nCreate a flag that identifies whether or not it’s a phone visit. HINT: Use the str_detect or str_starts function from the stringr package within if_else.\nFilter the act data to find QSDT dates starting with “2012”. HINT: Use the str_detect, or str_starts function from the stringr package.\nCreate a vector of subject IDs (SUBJID) from 1 to 20. Turn this into a suitable USUBJID format for study “GSK456789” (i.e. “GSK456789:000001” etc.) HINT: Use the appropriate function from the stringr package.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#working-with-dates-and-the-lubridate-package",
    "href": "06_basic_data_processing.html#working-with-dates-and-the-lubridate-package",
    "title": "6  Data Handling",
    "section": "6.14 Working with Dates and the lubridate Package",
    "text": "6.14 Working with Dates and the lubridate Package\nThe lubridate package is another of the tidyverse packages and provides a number of useful functions for working with dates and times, supplementing other functions that were already built into R before the tidyverse came along. As with forcats and stringr the lubridate package is installed as part of the tidyverse but we have to load it separately. Unlike forcats and stringr, however, functions in lubridate don’t have a prefix.\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nobjects(\"package:lubridate\")\n\n  [1] \"%--%\"              \"%m-%\"              \"%m+%\"             \n  [4] \"%within%\"          \"add_with_rollback\" \"am\"               \n  [7] \"Arith\"             \"as_date\"           \"as_datetime\"      \n [10] \"as.difftime\"       \"as.duration\"       \"as.interval\"      \n [13] \"as.period\"         \"ceiling_date\"      \"Compare\"          \n [16] \"cyclic_encoding\"   \"date\"              \"Date\"             \n [19] \"date_decimal\"      \"date&lt;-\"            \"day\"              \n [22] \"day&lt;-\"             \"days\"              \"days_in_month\"    \n [25] \"ddays\"             \"decimal_date\"      \"dhours\"           \n [28] \"dmicroseconds\"     \"dmilliseconds\"     \"dminutes\"         \n [31] \"dmonths\"           \"dmy\"               \"dmy_h\"            \n [34] \"dmy_hm\"            \"dmy_hms\"           \"dnanoseconds\"     \n [37] \"dpicoseconds\"      \"dseconds\"          \"dst\"              \n [40] \"duration\"          \"dweeks\"            \"dyears\"           \n [43] \"dym\"               \"epiweek\"           \"epiyear\"          \n [46] \"fast_strptime\"     \"fit_to_timeline\"   \"floor_date\"       \n [49] \"force_tz\"          \"force_tzs\"         \"format_ISO8601\"   \n [52] \"guess_formats\"     \"hm\"                \"hms\"              \n [55] \"hour\"              \"hour&lt;-\"            \"hours\"            \n [58] \"int_aligns\"        \"int_diff\"          \"int_end\"          \n [61] \"int_end&lt;-\"         \"int_flip\"          \"int_length\"       \n [64] \"int_overlaps\"      \"int_shift\"         \"int_standardize\"  \n [67] \"int_start\"         \"int_start&lt;-\"       \"intersect\"        \n [70] \"interval\"          \"is.Date\"           \"is.difftime\"      \n [73] \"is.duration\"       \"is.instant\"        \"is.interval\"      \n [76] \"is.period\"         \"is.POSIXct\"        \"is.POSIXlt\"       \n [79] \"is.POSIXt\"         \"is.timepoint\"      \"is.timespan\"      \n [82] \"isoweek\"           \"isoyear\"           \"lakers\"           \n [85] \"leap_year\"         \"local_time\"        \"make_date\"        \n [88] \"make_datetime\"     \"make_difftime\"     \"mday\"             \n [91] \"mday&lt;-\"            \"mdy\"               \"mdy_h\"            \n [94] \"mdy_hm\"            \"mdy_hms\"           \"microseconds\"     \n [97] \"milliseconds\"      \"minute\"            \"minute&lt;-\"         \n[100] \"minutes\"           \"month\"             \"month&lt;-\"          \n[103] \"ms\"                \"my\"                \"myd\"              \n[106] \"NA_Date_\"          \"NA_POSIXct_\"       \"nanoseconds\"      \n[109] \"now\"               \"origin\"            \"parse_date_time\"  \n[112] \"parse_date_time2\"  \"period\"            \"period_to_seconds\"\n[115] \"picoseconds\"       \"pm\"                \"POSIXct\"          \n[118] \"pretty_dates\"      \"qday\"              \"qday&lt;-\"           \n[121] \"quarter\"           \"reclass_date\"      \"reclass_timespan\" \n[124] \"rollback\"          \"rollbackward\"      \"rollforward\"      \n[127] \"round_date\"        \"second\"            \"second&lt;-\"         \n[130] \"seconds\"           \"seconds_to_period\" \"semester\"         \n[133] \"setdiff\"           \"show\"              \"stamp\"            \n[136] \"stamp_date\"        \"stamp_time\"        \"time_length\"      \n[139] \"today\"             \"tz\"                \"tz&lt;-\"             \n[142] \"union\"             \"wday\"              \"wday&lt;-\"           \n[145] \"week\"              \"week&lt;-\"            \"weeks\"            \n[148] \"with_tz\"           \"yday\"              \"yday&lt;-\"           \n[151] \"ydm\"               \"ydm_h\"             \"ydm_hm\"           \n[154] \"ydm_hms\"           \"year\"              \"year&lt;-\"           \n[157] \"years\"             \"ym\"                \"ymd\"              \n[160] \"ymd_h\"             \"ymd_hm\"            \"ymd_hms\"          \n[163] \"yq\"               \n\n\n\n6.14.1 Date Conversion\nAs with other software, R stores date data as numeric data and applies a format over the top so that the dates are human-readable. For the underlying numbers R follows the unix convention whereby time starts on 1st January 1970 (day 0). The character format is always the international date standard format, “yyyy-mm-dd”. To make use of the date functionality we often need to convert our dates from character to date format. It is worth noting, however, that functions such as read_sas can recognise date types and convert automatically.\nIn the spirit of functions having a single, simple purpose a significant proportion of the functions in the lubridate package simply convert various character date and/or time formats into a date/time format. For dates we must choose from a number of functions of the form, dmy (day-month-year). The choice of which depends on what order our day, month and year are provided in. The functions are all reasonably intelligent and can handle a variety of separators (e.g. “/” or “-”); numeric and character specification of month; and both 2 and 4 digit years. Some examples are provided below.\n\n# Some different ways of displaying the same date\na_date_europe &lt;- \"15-11-17\"\na_date_US &lt;- \"11-15-17\"\na_date_GSK &lt;- \"15-Nov-17\"\na_date_programming_standard &lt;- \"2017-11-15\"\n\n# Some lubridate functions for converting each of thes dates\ndmy(a_date_europe)\n\n[1] \"2017-11-15\"\n\nmdy(a_date_US)\n\n[1] \"2017-11-15\"\n\ndmy(a_date_GSK)\n\n[1] \"2017-11-15\"\n\nymd(a_date_programming_standard)\n\n[1] \"2017-11-15\"\n\n\nThe lubridate package has a similar set of functions for working with times and date-time. Some further examples are provided below.\n\n# A time\nlunch_time &lt;- \"12:00:00\"\nhms(lunch_time)\n\n[1] \"12H 0M 0S\"\n\n# A date-time\nnew_year_party_start &lt;- \"31-12-2017 21:30:00\"\ndmy_hms(new_year_party_start, tz = \"UTC\")\n\n[1] \"2017-12-31 21:30:00 UTC\"\n\n\n\n\n6.14.2 Date/time Utilities\nOnce we have converted our date/time into the appropriate format we can make use of a number of utility functions in order to process the dates. A few examples are provided below.\n\n# Today is a\nweekdays(today())\n\n[1] \"Thursday\"\n\n# When can I leave?\ntoday() + hours(3)\n\n[1] \"2026-01-08 03:00:00 UTC\"\n\n# DBF is today, how long until SAC?\nDBF &lt;- today()\nSAC &lt;- DBF + weeks(5)\nSAC\n\n[1] \"2026-02-12\"\n\n# How many days until Christmas?\ndifftime(ymd(\"2017-12-25\"), today()) \n\nTime difference of -2936 days",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "06_basic_data_processing.html#transmute",
    "href": "06_basic_data_processing.html#transmute",
    "title": "6  Data Handling",
    "section": "6.15 Transmute",
    "text": "6.15 Transmute\nAll of the functions that we’ve seen in recent sections can be used with the mutate function. They can also be used with a counterpart of mutate, transmute. The difference between mutate and transmute is that when we use transmute, the newly created columns are kept but the old ones are dropped. Occasionally this can be useful if summarising a large number of variables into a total score or similar.\n\ntransmute(vs, \n          Height_m2 = (HEIGHT/100) ^2, \n          BMI = WEIGHT / Height_m2)\n\n# A tibble: 30 × 2\n   Height_m2   BMI\n       &lt;dbl&gt; &lt;dbl&gt;\n 1      2.72  32.3\n 2      3.20  31.2\n 3      3.31  24.5\n 4      2.76  33.0\n 5      2.86  25.8\n 6      2.69  24.5\n 7      2.46  43.4\n 8      3.57  28.3\n 9      2.40  22.5\n10      2.92  30.1\n# ℹ 20 more rows",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Handling</span>"
    ]
  },
  {
    "objectID": "07_magrittr.html",
    "href": "07_magrittr.html",
    "title": "7  Piping",
    "section": "",
    "text": "7.1 The Basics of Piping\nThe arrival of the tidyverse has popularised a new way of programming in R, piping. Specifically it has popularised the magrittr pipe, %&gt;%, so-called because it originated in a package called {magrittr}.\nThe pipe is essentially an alternative to nesting that allows functions to be chained together such that the output of one function becomes the first input of the next. It takes some getting used to but the end-result is a lot less brackets and much more readable code.\nOver the past few years, the {magrittr} package pipe became so popular that a native pipe, |&gt;, was introduced from R-4.1.0. In these training materials we still use the magrittr pipe for backwards compatibility but changes are anticipated during 2025. It is worth noting the the Tidyverse style guide now recommends the use of the native pipe instead of the {magrittr} pipe.\nTo see how it works we will use some theophylline data. The aim here is to extract baseline concentration values for each subject. We will use filter and select. Without the pipe there are two ways we might do this: 1. nesting; 2. via intermediary datasets.\n# tidyverse loads the dplyr package for filter and select (and the pipe)\nlibrary(tidyverse) \n# Start with the theoph data\nhead(theoph)\n\n# A tibble: 6 × 5\n  SUBJID    WT  DOSE  TIME  CONC\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  79.6  4.02  0     0.74\n2      1  79.6  4.02  0.25  2.84\n3      1  79.6  4.02  0.57  6.57\n4      1  79.6  4.02  1.12 10.5 \n5      1  79.6  4.02  2.02  9.66\n6      1  79.6  4.02  3.82  8.58\n\n# Method 1: nesting (no one likes this)\nbl_conc &lt;- select(filter(theoph, TIME == 0), SUBJID, CONC)\n# Now check it worked\nhead(bl_conc)\n\n# A tibble: 6 × 2\n  SUBJID  CONC\n   &lt;dbl&gt; &lt;dbl&gt;\n1      1  0.74\n2      2  0   \n3      3  0   \n4      4  0   \n5      5  0   \n6      6  0   \n\n# Method 2: intermediary datasets\n# (better, but leaves us with an object, bl_rows, that we may not want)\nbl_rows &lt;- filter(theoph, TIME == 0)\nbl_conc &lt;- select(bl_rows, SUBJID, CONC)\n# Now check it worked\nhead(bl_conc)\n\n# A tibble: 6 × 2\n  SUBJID  CONC\n   &lt;dbl&gt; &lt;dbl&gt;\n1      1  0.74\n2      2  0   \n3      3  0   \n4      4  0   \n5      5  0   \n6      6  0\nThe magrittr pipe provides a more readable syntax, similar to method 2 but avoids the intermediary dataset. The theoph data are piped in as the first argument to the filter function and so we don’t need to specify it again, leaving only the row subset that we wish to apply. The filtered data are then piped into the select function in order to reduce-down the number of columns. As the data are piped in we again avoid having to provide the data as the first argument to select, leaving us to specify the columns that we wish to keep (or drop).\nbl_conc &lt;- theoph %&gt;%      # Take the theoph data, then ...\n  filter(TIME == 0) %&gt;%   # ... filter the rows, then ... \n  select(SUBJID, CONC)    # ... select columns\n\n# Now check it worked\nbl_conc %&gt;% head\n\n# A tibble: 6 × 2\n  SUBJID  CONC\n   &lt;dbl&gt; &lt;dbl&gt;\n1      1  0.74\n2      2  0   \n3      3  0   \n4      4  0   \n5      5  0   \n6      6  0",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Piping</span>"
    ]
  },
  {
    "objectID": "07_magrittr.html#the-pipe-and-the-tidyverse",
    "href": "07_magrittr.html#the-pipe-and-the-tidyverse",
    "title": "7  Piping",
    "section": "7.2 The Pipe and the tidyverse",
    "text": "7.2 The Pipe and the tidyverse\nThe tidyverse has been designed with piping in mind. Each of the functions that we have seen thus far (and those that we are about to look at) takes a data frame as the first argument of the function, processes the data frame somehow, then outputs another data frame. For this reason we will continue to use the pipe for the remainder of this course (after some exercises).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Piping</span>"
    ]
  },
  {
    "objectID": "07_magrittr.html#more-on-piping",
    "href": "07_magrittr.html#more-on-piping",
    "title": "7  Piping",
    "section": "7.3 More on Piping",
    "text": "7.3 More on Piping\nPiping works best with functions for which the first input argument and the output are of the same type, for example data frames. However it is possible to pipe into any function argument using a dot/period, ..\n\n# Pipe into a statement\np_val &lt;- 0.049\np_val %&gt;%\n  cat(\"The p-value is\", .)\n\nThe p-value is 0.049\n\n# Pipe colours into a plot\n\"red\" %&gt;%\n  hist(rnorm(100), col = .) \n\n\n\n\n\n\n\n\nNOTE: When using R’s native pipe, we use an underscore, _, in place of the ..",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Piping</span>"
    ]
  },
  {
    "objectID": "07_magrittr.html#piping_ex",
    "href": "07_magrittr.html#piping_ex",
    "title": "7  Piping",
    "section": "7.4 EXERCISE",
    "text": "7.4 EXERCISE\n\nUse the pipe to create a new dataset called act_bl:\n\nExtract the randomisation records from the act data\nCalculate ACT total score and name this ACTBL. HINT: Use code from earlier exercise\nKeep only the USUBJID and ACTBL columns\n\nWrite this to a CSV called “act_bl.csv”",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Piping</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html",
    "href": "08_summaries_aggregation.html",
    "title": "8  Summaries and Aggregation",
    "section": "",
    "text": "8.1 Summary Statistics: summarise\nAs we might expect, R has a number of in-built functions that can be used to summarise data. These summary functions tend to be very granular and work directly with vectors (columns) of data. Typically we call these functions via the summarise function. The summarise function works just like mutate except that rather than create a new column, it summarises over all values in the column. We must therefore always provide summarise with functions that return a single value. Like transmute, the summarise function only returns the summarised columns, all other columns are ignored. As with mutate and transmute it helps to name the summarised data.\ndm %&gt;% \n  summarise(Mean_Age = mean(AGE), SD_Age = sd(AGE))\n\n# A tibble: 1 × 2\n  Mean_Age SD_Age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     50.4   15.3\nThere are many statistical functions in R, mostly contained within the “base” and “stats” packages. Generally the function purposes are self-evident. A common set of statistical summary functions is listed below:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#summary-statistics-summarise",
    "href": "08_summaries_aggregation.html#summary-statistics-summarise",
    "title": "8  Summaries and Aggregation",
    "section": "",
    "text": "mean\nmedian\nsd\nvar\nmin\nmax\nsum",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#missing-values",
    "href": "08_summaries_aggregation.html#missing-values",
    "title": "8  Summaries and Aggregation",
    "section": "8.2 Missing Values",
    "text": "8.2 Missing Values\nR is written in a way that forces us to think about missing values, which is a nice way of saying that they can be a pain to deal with:\n\nsome_vals &lt;- c(1, NA, 3)\nmean(some_vals)\n\n[1] NA\n\nmedian(some_vals)\n\n[1] NA\n\nmin(some_vals)\n\n[1] NA\n\n\nThankfully, each of the statistical summary functions has an argument, na.rm, which when set to TRUE allows us to remove missing values.\n\nsome_vals &lt;- c(1, NA, 3)\nmean(some_vals, na.rm = TRUE)\n\n[1] 2\n\nmedian(some_vals, na.rm = TRUE)\n\n[1] 2\n\nmin(some_vals, na.rm = TRUE)\n\n[1] 1\n\n\n\n8.2.1 Summarising with mutate\nNote that we can use functions such as mean and sd with mutate The effect is to summarise and then merge the result back on to the original data.\n\ndm %&gt;% \n  mutate(Mean_Age = mean(AGE), SD_Age = sd(AGE))\n\n# A tibble: 30 × 9\n   USUBJID            AGE SEX   COUNTRY RACE        ETHNIC ARM   Mean_Age SD_Age\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR A… NOT H… Comp…     50.4   15.3\n 2 STD123456:000002    28 M     FRA     WHITE       NOT H… Comp…     50.4   15.3\n 3 STD123456:000003    55 M     USA     BLACK OR A… NOT H… Comp…     50.4   15.3\n 4 STD123456:000004    35 F     GER     WHITE       HISPA… Comp…     50.4   15.3\n 5 STD123456:000005    30 F     IRE     WHITE       NOT H… Comp…     50.4   15.3\n 6 STD123456:000006    22 F     GER     WHITE       NOT H… Comp…     50.4   15.3\n 7 STD123456:000007    59 F     USA     WHITE       NOT H… Comp…     50.4   15.3\n 8 STD123456:000008    53 M     GER     WHITE       NOT H… GSK       50.4   15.3\n 9 STD123456:000009    60 F     USA     WHITE       NOT H… GSK       50.4   15.3\n10 STD123456:000010    48 M     USA     WHITE       NOT H… Comp…     50.4   15.3\n# ℹ 20 more rows",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#by-operations-group_by",
    "href": "08_summaries_aggregation.html#by-operations-group_by",
    "title": "8  Summaries and Aggregation",
    "section": "8.3 By Operations: group_by",
    "text": "8.3 By Operations: group_by\nR has always been able to calculate summary statistics for one variable by another but the creation of the dplyr package has enabled these “by” operations to take place within a consistent framework. We achieve the desired effect via the group_by function. But before we do any calculations, let’s look at what this function does.\n\ndm %&gt;% \n  group_by(ARM)\n\n# A tibble: 30 × 7\n# Groups:   ARM [2]\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 2 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 4 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 5 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 6 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 7 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n 8 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n\nA quick glance at the result above might suggest that nothing has happened. The data are not even sorted by the ARM variable. What has happened is that an attribute has been added to the data. Notice that in the printed result we see “Groups:   ARM [2]”. This tells us that the data are grouped by ARM and that the arm variable has 2 distinct (unique) values.\nWe can group by as many variables as we like. It doesn’t matter if they are continuous or discrete although clearly the latter makes more sense.\n\ndm %&gt;% \n  group_by(COUNTRY, SEX)\n\n# A tibble: 30 × 7\n# Groups:   COUNTRY, SEX [9]\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 2 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 4 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 5 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 6 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 7 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n 8 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#summary-statistics-continued",
    "href": "08_summaries_aggregation.html#summary-statistics-continued",
    "title": "8  Summaries and Aggregation",
    "section": "8.4 Summary Statistics Continued",
    "text": "8.4 Summary Statistics Continued\nThe main benefit of grouping by a variable(s) is so that we can summarise other variables by our grouping variable(s). Once our data are grouped we simply call the summarise function and the behaviour adapts accordingly.\n\ndm %&gt;% \n  group_by(ARM) %&gt;%\n  summarise(N = n())\n\n# A tibble: 2 × 2\n  ARM            N\n  &lt;chr&gt;      &lt;int&gt;\n1 Comparator    18\n2 GSK           12\n\n\nThe result is always a data frame. Adding more “by” variables simply results in more columns.\n\ndm %&gt;% \n  group_by(ARM, COUNTRY) %&gt;%\n  summarise(N = n())\n\n`summarise()` has grouped output by 'ARM'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 9 × 3\n# Groups:   ARM [2]\n  ARM        COUNTRY     N\n  &lt;chr&gt;      &lt;chr&gt;   &lt;int&gt;\n1 Comparator FRA         3\n2 Comparator GER         3\n3 Comparator IRE         4\n4 Comparator UK          2\n5 Comparator USA         6\n6 GSK        FRA         4\n7 GSK        GER         2\n8 GSK        IRE         2\n9 GSK        USA         4",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#other-uses-of-grouping",
    "href": "08_summaries_aggregation.html#other-uses-of-grouping",
    "title": "8  Summaries and Aggregation",
    "section": "8.5 Other Uses of Grouping",
    "text": "8.5 Other Uses of Grouping\nGrouping our data has no effect on column operations such as select and rename. It can, however, change the behaviour of functions such as filter and slice, which operate on rows. For example, when we call slice on grouped data the count resets for each “by” variable.\n\n# Find the first PK measurement for each subject\ntheoph %&gt;% \n  group_by(SUBJID) %&gt;%\n  slice(1)\n\n# A tibble: 12 × 5\n# Groups:   SUBJID [12]\n   SUBJID    WT  DOSE  TIME  CONC\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1  79.6  4.02     0  0.74\n 2      2  72.4  4.4      0  0   \n 3      3  70.5  4.53     0  0   \n 4      4  72.7  4.4      0  0   \n 5      5  54.6  5.86     0  0   \n 6      6  80    4        0  0   \n 7      7  64.6  4.95     0  0.15\n 8      8  70.5  4.53     0  0   \n 9      9  86.4  3.1      0  0   \n10     10  58.2  5.5      0  0.24\n11     11  65    4.92     0  0   \n12     12  60.5  5.3      0  0   \n\n# And the last\ntheoph %&gt;% \n  group_by(SUBJID) %&gt;%\n  slice(n())\n\n# A tibble: 12 × 5\n# Groups:   SUBJID [12]\n   SUBJID    WT  DOSE  TIME  CONC\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1  79.6  4.02  24.4  3.28\n 2      2  72.4  4.4   24.3  0.9 \n 3      3  70.5  4.53  24.2  1.05\n 4      4  72.7  4.4   24.6  1.15\n 5      5  54.6  5.86  24.4  1.57\n 6      6  80    4     23.8  0.92\n 7      7  64.6  4.95  24.2  1.15\n 8      8  70.5  4.53  24.1  1.25\n 9      9  86.4  3.1   24.4  1.12\n10     10  58.2  5.5   23.7  2.42\n11     11  65    4.92  24.1  0.86\n12     12  60.5  5.3   24.2  1.17\n\n\nIn the exercises we will practice using a variety of functions with grouped data.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#summarise",
    "href": "08_summaries_aggregation.html#summarise",
    "title": "8  Summaries and Aggregation",
    "section": "8.6 EXERCISE",
    "text": "8.6 EXERCISE\n\nCalculate the maximum concentration for each subject in the theoph data\nUse mutate and the act_long data to calculate the ACT Total score (ACTTOT) for each subject-visit combination by summing over QSSTRESN and save the output as act_basic.\n\nRemove the QSTEST, QSORRES and QSSTRESN variables\nEnsure that each record contains a unique ACT Total score for the subject-visit combination. HINT: Use slice\n\nDerive baseline (Visit 2) ACT Total scores for each subject using the act_basic data from the previous exercise\n\nRename ACTTOT to ACTBL\nKeep only the USUBJID and ACTBL columns\n\nUsing the act_full data, for each treatment-visit combination calculate\n\nThe number of subjects\nThe mean and standard deviation of the ACT Total Score\n\n\nExtra\n\nFilter the act_basic data such that it contains only subjects with a missing Week 24 Total Score and impute week 24 scores using the WOCF (Worst Observation Carried Forward) method by carrying forward their worst (minimum) Total Score from all visits up to that point. HINT: Use the any function to see if a subject has a Week 24 record, and then find the minimum Total Score to impute missing values.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "08_summaries_aggregation.html#updating-undoing-a-group_by",
    "href": "08_summaries_aggregation.html#updating-undoing-a-group_by",
    "title": "8  Summaries and Aggregation",
    "section": "8.7 Updating / Undoing a group_by",
    "text": "8.7 Updating / Undoing a group_by\nIt is important to note that by adding a grouping to our data we are making a permanent change to the attributes of our data. This could cause unexpected behaviour further down the line if we “forgot” that our data were grouped. It is easy to undo a grouping using the ungroup function.\n\n# Overwrite dm with a grouped version of dm\ndm &lt;- dm %&gt;% \n  group_by(ARM, COUNTRY) \ndm\n\n# A tibble: 30 × 7\n# Groups:   ARM, COUNTRY [9]\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 2 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 4 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 5 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 6 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 7 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n 8 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n# Remove the grouping\ndm &lt;- dm %&gt;%\n  ungroup()\ndm\n\n# A tibble: 30 × 7\n   USUBJID            AGE SEX   COUNTRY RACE                      ETHNIC   ARM  \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 2 STD123456:000002    28 M     FRA     WHITE                     NOT HIS… Comp…\n 3 STD123456:000003    55 M     USA     BLACK OR AFRICAN AMERICAN NOT HIS… Comp…\n 4 STD123456:000004    35 F     GER     WHITE                     HISPANI… Comp…\n 5 STD123456:000005    30 F     IRE     WHITE                     NOT HIS… Comp…\n 6 STD123456:000006    22 F     GER     WHITE                     NOT HIS… Comp…\n 7 STD123456:000007    59 F     USA     WHITE                     NOT HIS… Comp…\n 8 STD123456:000008    53 M     GER     WHITE                     NOT HIS… GSK  \n 9 STD123456:000009    60 F     USA     WHITE                     NOT HIS… GSK  \n10 STD123456:000010    48 M     USA     WHITE                     NOT HIS… Comp…\n# ℹ 20 more rows\n\n\nIn addition, each time we call the group_by function it overwrites the previous grouping. So rather than always ungrouping our data we can just re-group in order to slice and dice our data in different ways.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summaries and Aggregation</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html",
    "href": "09_setting_merging.html",
    "title": "9  Setting and Merging",
    "section": "",
    "text": "9.1 Setting: bind_rows\nWe can combine similarly structured data frames using the bind_rows function. This is equivalent to a “set” operation in SAS.\n# Generate two data frames\ninterim &lt;- crossing(SUBJID = 1:3, VISITNUM = 1:2)\npost_interim &lt;- crossing(SUBJID = 4:5, VISITNUM = 1:2)\n\n# What do they look like?\ninterim\n\n# A tibble: 6 × 2\n  SUBJID VISITNUM\n   &lt;int&gt;    &lt;int&gt;\n1      1        1\n2      1        2\n3      2        1\n4      2        2\n5      3        1\n6      3        2\n\npost_interim\n\n# A tibble: 4 × 2\n  SUBJID VISITNUM\n   &lt;int&gt;    &lt;int&gt;\n1      4        1\n2      4        2\n3      5        1\n4      5        2\n\n# Combine (set) the data frames\nfinal_data &lt;- bind_rows(interim, post_interim)\nfinal_data\n\n# A tibble: 10 × 2\n   SUBJID VISITNUM\n    &lt;int&gt;    &lt;int&gt;\n 1      1        1\n 2      1        2\n 3      2        1\n 4      2        2\n 5      3        1\n 6      3        2\n 7      4        1\n 8      4        2\n 9      5        1\n10      5        2\nThe bind_rows is relatively intelligent in that the columns do not need to match between the two data frames that we wish to combine. If columns appear in a different order, the order of the first data frame is used for the final output.\nIn the following example a baseline record is combined with a post-baseline record. The post-baseline record does not contain a “BASE” column but this appears in the final data with a missing value.\n# Generate two data frames\nbaseline &lt;- tibble(SUBJID = 1, VISITNUM = 1, BASE= 10, AVAL = 10)\npost_bl &lt;- tibble(SUBJID = 1, VISITNUM = 2, AVAL= 11)\n\nbind_rows(baseline, post_bl)\n\n# A tibble: 2 × 4\n  SUBJID VISITNUM  BASE  AVAL\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1        1    10    10\n2      1        2    NA    11",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html#binding-columns-bind_cols",
    "href": "09_setting_merging.html#binding-columns-bind_cols",
    "title": "9  Setting and Merging",
    "section": "9.2 Binding Columns bind_cols",
    "text": "9.2 Binding Columns bind_cols\nFor columns an equivalent function, bind_cols exists. So long as two data frames have the same number of rows we can use bind_cols to join them together. In the following example we should merge by USUBJID but let’s see what happens if we just stick the data together.\n\n# Simply stick the demography and vitals data together\n# Scary stuff! But it works since both have the same subjects in the same order\nbind_cols(dm, vs)\n\nNew names:\n• `USUBJID` -&gt; `USUBJID...1`\n• `USUBJID` -&gt; `USUBJID...8`\n\n\n# A tibble: 30 × 10\n   USUBJID...1    AGE SEX   COUNTRY RACE  ETHNIC ARM   USUBJID...8 HEIGHT WEIGHT\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1 STD123456:0…    32 F     UK      BLAC… NOT H… Comp… STD123456:…    165   88  \n 2 STD123456:0…    28 M     FRA     WHITE NOT H… Comp… STD123456:…    179  100  \n 3 STD123456:0…    55 M     USA     BLAC… NOT H… Comp… STD123456:…    182   81  \n 4 STD123456:0…    35 F     GER     WHITE HISPA… Comp… STD123456:…    166   91  \n 5 STD123456:0…    30 F     IRE     WHITE NOT H… Comp… STD123456:…    169   73.6\n 6 STD123456:0…    22 F     GER     WHITE NOT H… Comp… STD123456:…    164   66  \n 7 STD123456:0…    59 F     USA     WHITE NOT H… Comp… STD123456:…    157  107  \n 8 STD123456:0…    53 M     GER     WHITE NOT H… GSK   STD123456:…    189  101  \n 9 STD123456:0…    60 F     USA     WHITE NOT H… GSK   STD123456:…    155   54.1\n10 STD123456:0…    48 M     USA     WHITE NOT H… Comp… STD123456:…    171   88  \n# ℹ 20 more rows\n\n\nIn this case it worked, although we might wish to remove the USUBJID1 column after checking that all values are equal to those in the USUBJID column. The bind_cols function is useful for simulation but with real data a merge is usually more appropriate.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html#merging-joining",
    "href": "09_setting_merging.html#merging-joining",
    "title": "9  Setting and Merging",
    "section": "9.3 Merging (Joining)",
    "text": "9.3 Merging (Joining)\nThe tidyverse terminology generally follows SQL where possible. We therefore talk about “joining” as opposed to “merging”. As is often the case in the tidyverse, different types of join are achieved by using different join functions. Here is a list of the current join functions:\n\n\nanti_join\ncross_join\nfull_join\ninner_join\nleft_join\nnest_join\nright_join\nsemi_join\nsql_join\nsql_semi_join\n\n\nThe *_join functions optimise the join for us so as long as we’re not performing a many-to-many merge no prior sorting is required. We need only specify which data frames we wish to join and which variables we wish to join by. In the following example we join together the demographics and vital signs data. Each of the join functions follows the same format of arguments: the first two arguments are the two data frames to join, the third argument is the by argument. This third argument requires a character vector of columns that we wish to join by.\n\nfull_join(dm, vs, by = \"USUBJID\")\n\n# A tibble: 30 × 9\n   USUBJID            AGE SEX   COUNTRY RACE          ETHNIC ARM   HEIGHT WEIGHT\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFR… NOT H… Comp…    165   88  \n 2 STD123456:000002    28 M     FRA     WHITE         NOT H… Comp…    179  100  \n 3 STD123456:000003    55 M     USA     BLACK OR AFR… NOT H… Comp…    182   81  \n 4 STD123456:000004    35 F     GER     WHITE         HISPA… Comp…    166   91  \n 5 STD123456:000005    30 F     IRE     WHITE         NOT H… Comp…    169   73.6\n 6 STD123456:000006    22 F     GER     WHITE         NOT H… Comp…    164   66  \n 7 STD123456:000007    59 F     USA     WHITE         NOT H… Comp…    157  107  \n 8 STD123456:000008    53 M     GER     WHITE         NOT H… GSK      189  101  \n 9 STD123456:000009    60 F     USA     WHITE         NOT H… GSK      155   54.1\n10 STD123456:000010    48 M     USA     WHITE         NOT H… Comp…    171   88  \n# ℹ 20 more rows\n\n\nIn the previous example we performed a full join. Observe what happens if we call this function on datasets with mismatching subject IDs.\n\ndm_head &lt;- dm %&gt;% head(10) %&gt;% select(-RACE, -ETHNIC) %&gt;% slice(-1)\nvs_missing &lt;- vs %&gt;% slice(1, 2, 4, 6, 9, 10)\ndm_head\n\n# A tibble: 9 × 5\n  USUBJID            AGE SEX   COUNTRY ARM       \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;     \n1 STD123456:000002    28 M     FRA     Comparator\n2 STD123456:000003    55 M     USA     Comparator\n3 STD123456:000004    35 F     GER     Comparator\n4 STD123456:000005    30 F     IRE     Comparator\n5 STD123456:000006    22 F     GER     Comparator\n6 STD123456:000007    59 F     USA     Comparator\n7 STD123456:000008    53 M     GER     GSK       \n8 STD123456:000009    60 F     USA     GSK       \n9 STD123456:000010    48 M     USA     Comparator\n\nvs_missing\n\n# A tibble: 6 × 3\n  USUBJID          HEIGHT WEIGHT\n  &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n1 STD123456:000001    165   88  \n2 STD123456:000002    179  100  \n3 STD123456:000004    166   91  \n4 STD123456:000006    164   66  \n5 STD123456:000009    155   54.1\n6 STD123456:000010    171   88  \n\n# Join together\nfull_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 10 × 7\n   USUBJID            AGE SEX   COUNTRY ARM        HEIGHT WEIGHT\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 STD123456:000002    28 M     FRA     Comparator    179  100  \n 2 STD123456:000003    55 M     USA     Comparator     NA   NA  \n 3 STD123456:000004    35 F     GER     Comparator    166   91  \n 4 STD123456:000005    30 F     IRE     Comparator     NA   NA  \n 5 STD123456:000006    22 F     GER     Comparator    164   66  \n 6 STD123456:000007    59 F     USA     Comparator     NA   NA  \n 7 STD123456:000008    53 M     GER     GSK            NA   NA  \n 8 STD123456:000009    60 F     USA     GSK           155   54.1\n 9 STD123456:000010    48 M     USA     Comparator    171   88  \n10 STD123456:000001    NA &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;          165   88  \n\n\nAll subjects are included but for the subjects with missing vitals the HEIGHT and WEIGHT values are shown as missing, as well as the AGE, SEX, COUNTRY and ARM values for the first subject in dm data.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html#left-right-and-inner-joins",
    "href": "09_setting_merging.html#left-right-and-inner-joins",
    "title": "9  Setting and Merging",
    "section": "9.4 Left, Right and Inner Joins",
    "text": "9.4 Left, Right and Inner Joins\nIf we perform a left join, only subjects present in dm_head are displayed with accompanying data joined from vs_missing.\n\nleft_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 9 × 7\n  USUBJID            AGE SEX   COUNTRY ARM        HEIGHT WEIGHT\n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 STD123456:000002    28 M     FRA     Comparator    179  100  \n2 STD123456:000003    55 M     USA     Comparator     NA   NA  \n3 STD123456:000004    35 F     GER     Comparator    166   91  \n4 STD123456:000005    30 F     IRE     Comparator     NA   NA  \n5 STD123456:000006    22 F     GER     Comparator    164   66  \n6 STD123456:000007    59 F     USA     Comparator     NA   NA  \n7 STD123456:000008    53 M     GER     GSK            NA   NA  \n8 STD123456:000009    60 F     USA     GSK           155   54.1\n9 STD123456:000010    48 M     USA     Comparator    171   88  \n\n\nIf we specify a right join, then only subjects that appear in vs_missing are joined on from dm_head, as seen below.\n\nright_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 6 × 7\n  USUBJID            AGE SEX   COUNTRY ARM        HEIGHT WEIGHT\n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 STD123456:000002    28 M     FRA     Comparator    179  100  \n2 STD123456:000004    35 F     GER     Comparator    166   91  \n3 STD123456:000006    22 F     GER     Comparator    164   66  \n4 STD123456:000009    60 F     USA     GSK           155   54.1\n5 STD123456:000010    48 M     USA     Comparator    171   88  \n6 STD123456:000001    NA &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;          165   88  \n\n\nAn inner join only returns complete records where data are present in both data frames for a particular subject.\n\ninner_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 5 × 7\n  USUBJID            AGE SEX   COUNTRY ARM        HEIGHT WEIGHT\n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 STD123456:000002    28 M     FRA     Comparator    179  100  \n2 STD123456:000004    35 F     GER     Comparator    166   91  \n3 STD123456:000006    22 F     GER     Comparator    164   66  \n4 STD123456:000009    60 F     USA     GSK           155   54.1\n5 STD123456:000010    48 M     USA     Comparator    171   88",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html#semi-joins-and-anti-joins",
    "href": "09_setting_merging.html#semi-joins-and-anti-joins",
    "title": "9  Setting and Merging",
    "section": "9.5 Semi Joins and Anti Joins",
    "text": "9.5 Semi Joins and Anti Joins\nIn cases such as the one above, where subjects appear in one dataset but not the other the semi_join and anti_join functions can be useful. The semi_join function returns all records in the first data frame that would be merged if a left/inner join were performed.\nThe anti_join function is effectively the converse to the semi_join and returns all the records that would not be merged.\n\n# Show the records in dm that would be merged if performing an inner/left join\nsemi_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 5 × 5\n  USUBJID            AGE SEX   COUNTRY ARM       \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;     \n1 STD123456:000002    28 M     FRA     Comparator\n2 STD123456:000004    35 F     GER     Comparator\n3 STD123456:000006    22 F     GER     Comparator\n4 STD123456:000009    60 F     USA     GSK       \n5 STD123456:000010    48 M     USA     Comparator\n\n# Show the records in dm that would NOT be merged if performing an inner/left join\nanti_join(dm_head, vs_missing, by = \"USUBJID\")\n\n# A tibble: 4 × 5\n  USUBJID            AGE SEX   COUNTRY ARM       \n  &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;     \n1 STD123456:000003    55 M     USA     Comparator\n2 STD123456:000005    30 F     IRE     Comparator\n3 STD123456:000007    59 F     USA     Comparator\n4 STD123456:000008    53 M     GER     GSK",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "09_setting_merging.html#merge",
    "href": "09_setting_merging.html#merge",
    "title": "9  Setting and Merging",
    "section": "9.6 EXERCISE",
    "text": "9.6 EXERCISE\n\nMerge the randomisation dates (contained within the sl data) onto the act data\nNow merge on the demography and vitals information and save this as act_main\n\nExtra\n\nAs in an earlier exercise, find subjects that have a missing Week 24 record and calculate the Worst Observation Carried Forward for these subjects. The resulting data should have a single row for each subject where VISITNUM and VISIT have been set to 60 and \"VISIT 6 (WEEK 24)\" respectively. An additional column should be labelled WOCF and be set to TRUE for these records. Bind these records back on to the main data.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Setting and Merging</span>"
    ]
  },
  {
    "objectID": "10_transposing.html",
    "href": "10_transposing.html",
    "title": "10  Transposing data",
    "section": "",
    "text": "10.1 The pivot_longer Function\nAnother common task when working with data is the transposition from/to long/wide formats. In the world of CDISC everything is in a long format. However we often need our data in a wide format in order to model or plot it. In the tidyverse, the tidyr package is required for restructuring our data. The tidyr package has many functions but we will focus on just two, pivot_longer and pivot_wider.\nThe pivot_longer function is use when we wish to go from a wide format to a long format. Once again the first argument is the data, which we will pipe in for the examples. We usually need to think long and hard about which variables we want to collapse, and which need to stay as they are…\n[THINKING]\nOnce we’re done thinking we must specify which variables we wish to stack together. Selecting variables can be done using the c function to name specif columns, or by using the same tidy_select group of functions (help(select_helpers)) that are available to us when using the select function (e.g. starts_with, contains, etc.). We can also specify the variables that we don’t want to stack together using a minus sign.\nvs %&gt;% \n  pivot_longer(cols = c(HEIGHT,WEIGHT))\n\n# A tibble: 60 × 3\n   USUBJID          name   value\n   &lt;chr&gt;            &lt;chr&gt;  &lt;dbl&gt;\n 1 STD123456:000001 HEIGHT 165  \n 2 STD123456:000001 WEIGHT  88  \n 3 STD123456:000002 HEIGHT 179  \n 4 STD123456:000002 WEIGHT 100  \n 5 STD123456:000003 HEIGHT 182  \n 6 STD123456:000003 WEIGHT  81  \n 7 STD123456:000004 HEIGHT 166  \n 8 STD123456:000004 WEIGHT  91  \n 9 STD123456:000005 HEIGHT 169  \n10 STD123456:000005 WEIGHT  73.6\n# ℹ 50 more rows\n\n# Alternatively\n# vs %&gt;% \n#   pivot_longer(cols = HEIGHT:WEIGHT)\n# Or else specify columns not to collapse using -\n# vs %&gt;% \n#   pivot_longer(cols = -USUBJID)\nAs we can see, the stacking operation has created two new columns to replace the ones that we stacked:\nWe can control the naming of these new columns using names_to and values_to. The argument names pretty much speak for themselves. But here is an example for which we label using CDISC terminology.\n# Make my vitals data CDISCy\nvs %&gt;% \n  pivot_longer(-USUBJID, names_to = \"VSTESTCD\", values_to = \"VSORRES\")\n\n# A tibble: 60 × 3\n   USUBJID          VSTESTCD VSORRES\n   &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt;\n 1 STD123456:000001 HEIGHT     165  \n 2 STD123456:000001 WEIGHT      88  \n 3 STD123456:000002 HEIGHT     179  \n 4 STD123456:000002 WEIGHT     100  \n 5 STD123456:000003 HEIGHT     182  \n 6 STD123456:000003 WEIGHT      81  \n 7 STD123456:000004 HEIGHT     166  \n 8 STD123456:000004 WEIGHT      91  \n 9 STD123456:000005 HEIGHT     169  \n10 STD123456:000005 WEIGHT      73.6\n# ℹ 50 more rows",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transposing data</span>"
    ]
  },
  {
    "objectID": "10_transposing.html#the-pivot_longer-function",
    "href": "10_transposing.html#the-pivot_longer-function",
    "title": "10  Transposing data",
    "section": "",
    "text": "The names column contains the original column names\nThe values column stores the values",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transposing data</span>"
    ]
  },
  {
    "objectID": "10_transposing.html#the-pivot_wider-function",
    "href": "10_transposing.html#the-pivot_wider-function",
    "title": "10  Transposing data",
    "section": "10.2 The pivot_wider Function",
    "text": "10.2 The pivot_wider Function\nThe pivot_wider function is used when we wish to go from a long format to a wide format. Once again we pass in the data as the first argument. As the converse of the pivot_longer function we specify a names_*from* and a values_*from* argument to identify the column that currently stores the names for our new columns (names_from), and the one that currently stores the values (values_from). The remaining columns are unaffected.\n\n# Count the number of subjects in each treatment arm\nbig_n &lt;- dm %&gt;%\n  group_by(ARM) %&gt;%\n  summarise(N = n())\nbig_n\n\n# A tibble: 2 × 2\n  ARM            N\n  &lt;chr&gt;      &lt;int&gt;\n1 Comparator    18\n2 GSK           12\n\n# Now transpose such that each treatment is in a separate column\nbig_n %&gt;%\n  pivot_wider(names_from = ARM, values_from = N)\n\n# A tibble: 1 × 2\n  Comparator   GSK\n       &lt;int&gt; &lt;int&gt;\n1         18    12",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transposing data</span>"
    ]
  },
  {
    "objectID": "10_transposing.html#transpose",
    "href": "10_transposing.html#transpose",
    "title": "10  Transposing data",
    "section": "10.3 EXERCISE",
    "text": "10.3 EXERCISE\n\nCreate a data frame, act_sum, by transposing the individual ACT question scores in the act data frame in order to calculate the ACT Total Score (sum of the questions).\n\nFirst stack the scores together using pivot_longer().\nThen calculate total ACTTOT for each subject and visit combination. The resulting act_sum data frame should look like this:\n\n\n\n\n# A tibble: 165 × 4\n# Groups:   USUBJID, VISITNUM [165]\n  USUBJID          VISITNUM VISIT                          ACTTOT\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                           &lt;dbl&gt;\n1 STD123456:000001       10 VISIT 1 (SCREENING)                16\n2 STD123456:000001       20 VISIT 2 (RANDOMISATION)            16\n3 STD123456:000001       30 VISIT 3 (PHONE CALL 1 WEEK 6)      13\n4 STD123456:000001       40 VISIT 4 (WEEK 12)                  15\n5 STD123456:000001       50 VISIT 5 (PHONE CALL 2 WEEK 18)     14\n6 STD123456:000001       60 VISIT 6 (WEEK 24)                  17\n7 STD123456:000002       10 VISIT 1 (SCREENING)                15\n# ℹ 158 more rows\n\n\n\nAs in an earlier exercise, calculate summary statistics (n, Mean, Median, SD, Min and Max) by treatment and visit using the act_full data frame.\n\nCreate a data frame, act_stats, by transposing the data such that the rows contain the summary statistics and the values for each treatment appear in a separate column. Hint: first use pivot_longer() to create a stats and values column and then pivot_wider() to create a column for each treatment. The resulting act_stats data frame should look like this:\n\n\n\n\n# A tibble: 42 × 5\n# Groups:   VISITNUM [7]\n  VISITNUM VISIT                   Stat   Comparator   GSK\n     &lt;dbl&gt; &lt;chr&gt;                   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1       10 VISIT 1 (SCREENING)     n           14    10   \n2       10 VISIT 1 (SCREENING)     Mean        17.1  16.6 \n3       10 VISIT 1 (SCREENING)     Median      17    15.5 \n4       10 VISIT 1 (SCREENING)     SD           1.41  2.01\n5       10 VISIT 1 (SCREENING)     Min         15    15   \n6       10 VISIT 1 (SCREENING)     Max         19    20   \n7       20 VISIT 2 (RANDOMISATION) n           18    12   \n# ℹ 35 more rows\n\n\nExtra\n\nRe-do question 2 but format the summary statistics such that the mean and median are given to 1 decimal place, the standard deviation to 2 decimal places and n, min and max are given as integers. HINT: Use the format function",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transposing data</span>"
    ]
  },
  {
    "objectID": "11_statistical_modelling.html",
    "href": "11_statistical_modelling.html",
    "title": "11  Introduction to Statistical Modelling",
    "section": "",
    "text": "11.1 A Simple Linear Model\nThe core purpose of R is to provide a programming framework for statistical modelling. Perhaps for this reason, the basics of statistical modelling have not been touched by the tidyverse. As we shall see, however, the modelr and broom packages can help us better-process model output.\nAll forms of model follow a similar specification in R so let’s start with the simplest, the linear model. This can be fitted using the lm function. To demonstrate how lm works we first merge/join the demography and vitals data frame together to create a population dataset.\npop &lt;- inner_join(dm, vs, by = \"USUBJID\")\npop\n\n# A tibble: 30 × 9\n   USUBJID            AGE SEX   COUNTRY RACE          ETHNIC ARM   HEIGHT WEIGHT\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 STD123456:000001    32 F     UK      BLACK OR AFR… NOT H… Comp…    165   88  \n 2 STD123456:000002    28 M     FRA     WHITE         NOT H… Comp…    179  100  \n 3 STD123456:000003    55 M     USA     BLACK OR AFR… NOT H… Comp…    182   81  \n 4 STD123456:000004    35 F     GER     WHITE         HISPA… Comp…    166   91  \n 5 STD123456:000005    30 F     IRE     WHITE         NOT H… Comp…    169   73.6\n 6 STD123456:000006    22 F     GER     WHITE         NOT H… Comp…    164   66  \n 7 STD123456:000007    59 F     USA     WHITE         NOT H… Comp…    157  107  \n 8 STD123456:000008    53 M     GER     WHITE         NOT H… GSK      189  101  \n 9 STD123456:000009    60 F     USA     WHITE         NOT H… GSK      155   54.1\n10 STD123456:000010    48 M     USA     WHITE         NOT H… Comp…    171   88  \n# ℹ 20 more rows\nNow let’s model weight as a function of height. In order to do so we call the lm function and provide two arguments: the data and the model formula. The model formula is specified using a tilde, ~. The dependent variable is placed to the left of the tilde and any independent (explanatory) variables are placed to the right. In the example below we save the model output with a name. We must do so if we wish to use the results, for example to create plots of the residuals.\n# Fit the model\npop_lm &lt;- lm(WEIGHT ~ HEIGHT, data = pop)\n# The default \"print\" for the model\npop_lm\n\n\nCall:\nlm(formula = WEIGHT ~ HEIGHT, data = pop)\n\nCoefficients:\n(Intercept)       HEIGHT  \n   -27.9264       0.6618\nThe example above fits a model of the form, WEIGHT = intercept + alpha*HEIGHT, where the intercept and alpha parameters are estimated by the model.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Statistical Modelling</span>"
    ]
  },
  {
    "objectID": "11_statistical_modelling.html#a-simple-linear-model",
    "href": "11_statistical_modelling.html#a-simple-linear-model",
    "title": "11  Introduction to Statistical Modelling",
    "section": "",
    "text": "11.1.1 Adding Terms\nIf we have more than one explanatory variable we use a plus, +, to add in the additional terms.\n\n# Fit the model\npop_lm2 &lt;- lm(WEIGHT ~ HEIGHT + AGE, data = pop)\npop_lm2\n\n\nCall:\nlm(formula = WEIGHT ~ HEIGHT + AGE, data = pop)\n\nCoefficients:\n(Intercept)       HEIGHT          AGE  \n   -47.5819       0.6798       0.3302  \n\n\n\n\n11.1.2 Categorical Variables\nWhen modelling, R uses the data type to determine which variables are numeric and which are discrete / categorical. This means that we need to ensure that the data are of the right type before fitting in the model. If we have categorical data stored as numeric then we can use the factor function to convert it to categorical.\nWhen fitting categorical variables, the first level of the factor is set as the base and all other levels are compared against this level. In order to change the order (and hence the base level) we can use a forcats function such as fct_relevel, which moves any given levels to the start of the queue. For readability it is generally advisable to do this in the data, as opposed to within the modelling step.\n\n#library(forcats)\n# Compare all countries against the US so change the order of levels in the data\npop &lt;- pop %&gt;%\n  # Move USA to the front\n  mutate(COUNTRY = fct_relevel(COUNTRY, \"USA\"))\n# To see what has happened:\n pop%&gt;%pull(COUNTRY)\n\n [1] UK  FRA USA GER IRE GER USA GER USA USA USA FRA IRE USA FRA USA FRA IRE USA\n[20] FRA GER GER IRE FRA USA FRA IRE IRE UK  USA\nLevels: USA FRA GER IRE UK\n\n# Fit the model - we now have a coefficient for all countries except USA\npop_lm3 &lt;- lm(WEIGHT ~ HEIGHT + AGE + COUNTRY , data = pop)\npop_lm3\n\n\nCall:\nlm(formula = WEIGHT ~ HEIGHT + AGE + COUNTRY, data = pop)\n\nCoefficients:\n(Intercept)       HEIGHT          AGE   COUNTRYFRA   COUNTRYGER   COUNTRYIRE  \n   -61.4822       0.6999       0.4014      14.9240       3.7707       8.4995  \n  COUNTRYUK  \n    16.8185  \n\n\n\n\n11.1.3 Interaction Terms\nWe can fit interaction terms using a colon, :. If we also want to include the base terms that make up the interaction term we can instead use the shorthand, *.\n\npop_lm_int &lt;- lm(WEIGHT ~ HEIGHT + AGE + HEIGHT:AGE, data = pop)\n# Or equivalently\npop_lm_int &lt;- lm(WEIGHT ~ HEIGHT*AGE, data = pop)\npop_lm_int\n\n\nCall:\nlm(formula = WEIGHT ~ HEIGHT * AGE, data = pop)\n\nCoefficients:\n(Intercept)       HEIGHT          AGE   HEIGHT:AGE  \n  -291.6603       2.1181       4.8607      -0.0267  \n\n\n\n\n11.1.4 Where the tidyverse Fits in\nEverything we’ve seen thus far is available “out of the box”. Most of what we’re about to see is implemented via two tidyverse packages, modelr and broom. The modelr package is one that allows us to more easily extract additional information from the model such as the Root Mean Square Error. The package also contains a number of useful utilities for resampling/bootstrapping and for implementing k-fold cross validation. Sadly, we don’t have the time to cover these features on this course. The broom package provides a set of helpful utilities for turning the standard R model output into data frames. SAS users might compare the functionality to that of SAS’ “ODS” feature.\nIn the following sections we use a combination of functions that are part of the base, stats, modelr and broom packages. It’s generally not worth worrying about what function is contained in what package so the easiest thing to do is to load modelr and broom each time you begin modelling (base and stats are always loaded when you start R in interactive mode). Both packages are installed as part of the tidyverse but not automatically loaded so we must do so manually.\n\n# Load the packages\nlibrary(modelr)\nlibrary(broom)\n\n\n\n11.1.5 Checking the Model Fit\nOnce we have fitted our model and saved it as an R object there are a number of different ways with which we can extract information. First of all the glance function produces a data frame where each column is a different model fit statistic.\n\nglance(pop_lm)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.186         0.157  15.7      6.38  0.0175     1  -124.  254.  259.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n11.1.6 Checking Assumptions\nAs well as looking at the fit we can check the model fit using the augment function. The augment function appends useful information such as the residuals and fitted values as columns to the original data.\n\naugment(pop_lm) %&gt;%\n  head\n\n# A tibble: 6 × 8\n  WEIGHT HEIGHT .fitted .resid   .hat .sigma .cooksd .std.resid\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1   88      165    81.3   6.72 0.0360   16.0 0.00354      0.435\n2  100      179    90.5   9.46 0.0663   15.9 0.0138       0.622\n3   81      182    92.5 -11.5  0.0870   15.8 0.0281      -0.767\n4   91      166    81.9   9.06 0.0346   15.9 0.00616      0.586\n5   73.6    169    83.9 -10.3  0.0336   15.9 0.00775     -0.668\n6   66      164    80.6 -14.6  0.0380   15.8 0.0177      -0.948\n\n\nIf we give the augmented data a name, we can use it to graphically check our model assumptions. We would need to load {ggplot2} to create the plot, if it were not already loaded.\n\n# Augment our data and save it\npop_data_modelled &lt;- augment(pop_lm)\n\n\n# Create a plot of the studentised residuals against fitted values\nlibrary(ggplot2)\n\nggplot(pop_data_modelled) + \n  geom_point(aes(x = .fitted, y = .std.resid)) +\n  geom_hline(yintercept=0, colour = \"red\")\n\n\n\n\n\n\n\n\n\n\n11.1.7 Extracting the Coefficients\nIn order to extract the coefficients for each of the parameters, along with the respective standard errors and p-values we can use the tidy function from the broom package. We simply provide the tidy function with the name of our model object and the function outputs a data frame containing the information we need.\n\ntidy(pop_lm)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -27.9      44.1      -0.633  0.532 \n2 HEIGHT         0.662     0.262     2.53   0.0175",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Statistical Modelling</span>"
    ]
  },
  {
    "objectID": "11_statistical_modelling.html#ch11.3",
    "href": "11_statistical_modelling.html#ch11.3",
    "title": "11  Introduction to Statistical Modelling",
    "section": "11.2 EXERCISE",
    "text": "11.2 EXERCISE\n\nFit a linear model of the Change from Baseline (ACTCHGBL) in ACT Total Score by treatment (ARM), age (AGE) and visit (VISITNUM) using the act_full data (exclude screening, baseline and early withdrawal data before fitting the model). HINT: these visits have VISITNUM values: of 10, 20 and 70.\nAsses your model fit by plotting the studentised residuals against the fitted values. HINT: use the following template ggplot(NAME_OF_DATA) + geom_point(aes(x = NAME_OF_X_VARIABLE, y = NAME_OF_Y_VARIABLE))\nProgrammatically find any significant (&lt; 0.05) coefficients",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Statistical Modelling</span>"
    ]
  },
  {
    "objectID": "11_statistical_modelling.html#other-types-of-model",
    "href": "11_statistical_modelling.html#other-types-of-model",
    "title": "11  Introduction to Statistical Modelling",
    "section": "11.3 Other Types of Model",
    "text": "11.3 Other Types of Model\nNow that we have a basic understanding of a model object and how we can extract useful information from it, let’s look at some of the other types of model that we might wish to fit in R.\n\n11.3.1 Generalised Linear Models\nIn order to fit generalised linear models we replace the lm function with the glm function. By default the glm function fits a generalised linear model using the normal (gaussian) family and so it is equivalent to lm. We can fit other distributions be changing the family argument to another distribution such as Poisson of binomial.\n\n# Model response using week 24 data\nw24 &lt;- act_full %&gt;% \n  filter(VISITNUM == 60)\nact_resp_mod &lt;- glm(data = w24, ACTRESP ~  ARM + AGE , \n                  family = \"binomial\")\ntidy(act_resp_mod)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   1.66      1.79       0.930   0.352\n2 ARMGSK        1.69      1.20       1.41    0.158\n3 AGE          -0.0190    0.0328    -0.580   0.562\n\n\n\n\n11.3.2 Mixed Model Repeated Measures (MMRM)\nHistorically, it has been relatively tricky to use R to fit the kind of MMRM models that we typically use in Pharma. A combination of packages could be used to achieve the desired results but subject matter expertise in both R and MMRM modelling was required! In 2022 the {mmrm} package was released. This package was built by Statisticians from within the pharmaceutical industry with copyright shared between several leading pharmaceutical companies (see https://openpharma.github.io/mmrm/latest-tag/).\nThe {mmrm} package provides a namesake mmrm function that simplifies the MMRM model fit. Model information can be extracted using {broom} in exactly the same way as we have seen for linear models and generalised linear models.\n\nlibrary(mmrm)\n\n# Model to be fitted to scheduled post-BL 'change from BL' data\nact_post_bl &lt;- act_full %&gt;% \n  filter(20 &lt; VISITNUM, VISITNUM &lt; 70) %&gt;% \n  # Visit must be a factor, not character.  \n  # VISIT 3 will be baseline for comparisons as first factor level\n  mutate(visit_factor = factor(VISIT)) # careful of levels in general case!\n\n# Fit unstructured covariance model which assumes:\n# REML: `reml = TRUE`\n# Satterthwaite DoF: `control = mmrm_control()`\nmmrm_mod &lt;- mmrm(\n  data = act_post_bl,\n  ACTCHGBL ~  ARM + visit_factor + us(visit_factor | USUBJID)\n)\ntidy(mmrm_mod)\n\n# A tibble: 5 × 6\n  term                                estimate std.error    df statistic p.value\n  &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)                            2.18      0.744  30.7     2.92  0.00645\n2 ARMGSK                                 1.23      1.10   27.5     1.12  0.274  \n3 visit_factorVISIT 4 (WEEK 12)         -0.947     0.841  25.4    -1.13  0.270  \n4 visit_factorVISIT 5 (PHONE CALL 2 …   -0.407     0.708  25.3    -0.575 0.570  \n5 visit_factorVISIT 6 (WEEK 24)          1.15      0.917  26.0     1.25  0.222  \n\n\nChanging standard options is remarkably easy with the {mmrm} package. For example switching between REML and ML estimation, or making a Kenward-Roger adjustment to degrees of freedom.\n\nmmrm_mod_kw &lt;- mmrm(\n  data = act_post_bl,\n  ACTCHGBL ~  ARM + visit_factor + us(visit_factor | USUBJID),\n  method = \"Kenward-Roger\"\n)\ntidy(mmrm_mod_kw)\n\n# A tibble: 5 × 6\n  term                                estimate std.error    df statistic p.value\n  &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)                            2.18      0.760  30.7     2.86  0.00749\n2 ARMGSK                                 1.23      1.20   27.5     1.03  0.314  \n3 visit_factorVISIT 4 (WEEK 12)         -0.947     0.808  25.4    -1.17  0.252  \n4 visit_factorVISIT 5 (PHONE CALL 2 …   -0.407     0.680  25.3    -0.599 0.554  \n5 visit_factorVISIT 6 (WEEK 24)          1.15      0.868  26.0     1.32  0.198  \n\n\nThe package can be combined with the popular {emmeans} package in order to extract estimated marginal means (AKA “least-square means”).\n\nlibrary(emmeans)\n\nmmrm() registered as emmeans extension\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\n# Pass the emmeans function the model object and the respective marginal means\n# In this case treatment by week (arm by visit)\nlsmeans_by_visit &lt;- emmeans(mmrm_mod_kw, ~ ARM | visit_factor)\n\n# Equivalently:\n#lsmeans_by_visit &lt;- emmeans(mmrm_mod_kw, \"ARM\", by= \"visit_factor\")\n# Pretty much equivalently (the attribute difference is beyond course scope)\n#lsmeans_by_visit &lt;- lsmeans(mmrm_mod_kw, \"ARM\", by= \"visit_factor\")\n\nlsmeans_by_visit\n\nvisit_factor = VISIT 3 (PHONE CALL 1 WEEK 6):\n ARM        emmean    SE   df lower.CL upper.CL\n Comparator   2.18 0.760 30.7    0.625     3.73\n GSK          3.40 0.930 30.8    1.507     5.30\n\nvisit_factor = VISIT 4 (WEEK 12):\n ARM        emmean    SE   df lower.CL upper.CL\n Comparator   1.23 0.993 31.3   -0.797     3.25\n GSK          2.46 1.120 33.8    0.187     4.73\n\nvisit_factor = VISIT 5 (PHONE CALL 2 WEEK 18):\n ARM        emmean    SE   df lower.CL upper.CL\n Comparator   1.77 0.933 33.7   -0.128     3.66\n GSK          3.00 1.070 35.2    0.831     5.16\n\nvisit_factor = VISIT 6 (WEEK 24):\n ARM        emmean    SE   df lower.CL upper.CL\n Comparator   3.32 0.949 32.7    1.390     5.25\n GSK          4.55 1.070 34.5    2.381     6.72\n\nConfidence level used: 0.95 \n\n\n\n\n11.3.3 Survival Models\nIn order to model survival data we load the survival package. Although we must load the package each time we wish to use it, it is actually installed as part of the base distribution of R. Survival modelling follows a similar pattern to what we have seen already. The only difference is that instead of a single dependent variable we use the Surv function to combine a time variable and a censoring variable.\nHere is an example of fitting a Cox Proportional Hazards model using the in-built lung data.\n\nlibrary(survival)\n\n# Some example data from the survival package:\nhead(lung)   #see help('lung') for further information about the dataset\n\n  inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss\n1    3  306      2  74   1       1       90       100     1175      NA\n2    3  455      2  68   1       0       90        90     1225      15\n3    3 1010      1  56   1       0       90        90       NA      15\n4    5  210      2  57   1       1       90        60     1150      11\n5    1  883      2  60   1       0      100        90       NA       0\n6   12 1022      1  74   1       1       50        80      513       0\n\n# Fit the model\ncox_mod &lt;- coxph(Surv(time, status) ~ ph.ecog + age, data=lung)\ntidy(cox_mod)\n\n# A tibble: 2 × 5\n  term    estimate std.error statistic  p.value\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 ph.ecog   0.443    0.116        3.83 0.000129\n2 age       0.0113   0.00932      1.21 0.226",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Statistical Modelling</span>"
    ]
  }
]